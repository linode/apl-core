. ./.env
. ./.gce

alias d="docker"
alias k="kubectl"
alias ksk="kubectl -n kube-system"
alias ki="k -n ingress"
alias kis="k -n istio-system"
alias kys="k -n kyma-system"
alias ks="k -n system"
alias ksh="k -n shared"
alias km="k -n monitoring"
alias kt="k -n tillerless"
alias ka="kubectl --all-namespaces=true"
alias kaa="ka get po,rs,job,deploy,ds,statefulset,svc"
alias kap="ka get po"
alias kdel="k delete"
alias kcv="k config view"
alias kce="$EDITOR ~/.kube/config"
alias kcg="k config view | grep 'current-context:' | sed -n -e 's/^.*current-context: //p'"
alias kcu="k config use-context"
alias kp="k proxy &"

img=otomi/tools:1.15-kyma
containerId=helmfile-otomi-stack-kyma
d --version &>/dev/null
hasDocker=$?
d ps &> /dev/null
dockerRunning=$?

drun() {
  d run -it --rm -v $PWD:$PWD -v ~/.kube:/root/.kube -v /tmp:/tmp  -v ~/.config/gcloud/  /root/.config/gcloud/ -w $PWD $img $@
}
# if not has docker: ci
if [ $hasDocker -ne 0 ]; then
  alias h="helm"
  alias hf="helmfile"
else
  echo "Found docker client, assuming developer context."
  if [ $dockerRunning -eq 0 ]; then
    echo "Found docker running, will use $img instead of local tooling"
    unalias h &> /dev/null
    unalias hf &> /dev/null
    function helm() {
      drun helm --tls \
        --tls-ca-cert $HELM_TLS_CA_CERT \
        --tls-cert $HELM_TLS_CERT \
        --tls-key $HELM_TLS_KEY \
        $@
    }
    alias h="helm"
    function hf() {
      args="$@"
      drun sh -c "helmfile $args"
    }
  else
    echo "No docker daemon running. Please start and source aliases again."
  fi  
fi

alias hk="h delete --purge"
alias kk="killall kubectl"

function kpk() { ps aux | grep "$@" | awk '{print $2}' | xargs kill; }
function kad() { k delete "$@" --all; }
function kcns() { k config set-context $(k config current-context) --namespace="$@"; }
function hsk() { his --namespace=kube-system "$@"; }
function hm() { his --namespace=monitoring "$@"; }
function hin() { his --namespace=ingress "$@"; }
function hs() { his --namespace=system "$@"; }
function hsh() { his --namespace=shared "$@"; }

function kdnp() {
  for ns in default kube-system system monitoring ingress shared; do
    kad networkpolicy -n $ns
  done
}
# force erase all namespaces
function kkns() {
  k proxy &
  k get ns | grep Terminating | awk '{print $1}' | xargs -n1 -- bash -c 'kubectl get ns "$0" -o json | jq "del(.spec.finalizers[0])" > "$0.json"; curl -k -H "Content-Type: application/json" -X PUT --data-binary @"$0.json" "http://127.0.0.1:8001/api/v1/namespaces/$0/finalize" '
  kk
}
# erase entire stack but keep nodes
function kkc() {
  hk $(h ls --all --short) >/dev/null
  k delete ns --all
  kkns
}

alias kku="k label installation/kyma-installation action=uninstall --overwrite"
function kkk() {
  k delete -f https://github.com/kyma-project/kyma/releases/download/$KYMA_VERSION/kyma-installer-cluster.yaml
  k delete -f https://raw.githubusercontent.com/kyma-project/kyma/$KYMA_VERSION/installation/resources/tiller.yaml
  k delete all --all
  kkc
  k delete crd $(k get crd | egrep "istio|ory|kyma|coreos|knative|velero" | awk '{print $1}')
  ksk delete deploy tiller-deploy
  ksk delete job tiller-certs-job
  ksk delete secret tiller-secret
}

function hfd() { kcu gke_otomi-cloud_europe-west4_otomi-cloud-dev && hf -e dev $@ --concurrency=1 --skip-deps; }
function hfp() { kcu gke_otomi-cloud_europe-west4_otomi-cloud-prd && hf -e prd $@ --concurrency=1 --skip-deps; }