cluster:
  apiName: ''
  apiServer: ''
  domainSuffix: ''
  k8sVersion: '1.19'
  name: 'dev'
  otomiVersion: master
  provider: ''
  region: ''
kms:
  sops:
    # provider can be one of aws|azure|google|vault
    provider: ''
    aws:
      clientID: ''
      clientSecret: ''
      keys: ''
    azure:
      tenantID: ''
      clientID: ''
      clientSecret: ''
      keys: ''
    google:
      accountJson: ''
      project: ''
      keys: ''
    vault:
      token: ''
oidc:
  clientID: ''
  clientSecret: ''
  adminGroupID: ''
  authUrl: ''
  issuer: ''
  teamAdminGroupID: ''
  tenantID: ''
  tokenUrl: ''
otomi:
  pullSecret: ''
  adminPassword: ''
  isMultitenant: true
customer:
  name: ''
dns:
  provider:
    # provide one of the following below: aws|azure|google
    # aws:
    #   region: 'eu-central-1'
    # azure:
    #   aadClientId: ''
    #   aadClientSecret: ''
    #   tenantId: '' # optional
    #   subscriptionId: '' # optional
    # google:
    #   serviceAccountKey: ''
    #   project: ''
charts:
  cert-manager:
    email: ''
    # stage defaults to 'staging'
    # stage: production
  external-dns:
    domainFilters:
      - ''
    # zoneIdFilters: []
  gitea:
    postgresqlPassword: ''
  keycloak:
    # keycloak is enabled by default
    # enabled: false
    idp:
      alias: otomi # shown on keycloak login page as a button
      # credentials that will be used by the apps' clients to access keycloak in the cluster:
      clientID: ''
      clientSecret: ''
    postgresqlPassword: '' # for now this needs to be set to avoid generating a new one each time
  loki:
    adminPassword: '' # used for log splitting by team
  nginx-ingress:
    private:
      enabled: false # enable to start a LB on the private network
  kubeapps:
    postgresqlPassword: '' # for now this needs to be set to avoid generating a new one each time
  oauth2-proxy: 
    config:
      cookieSecret: '' # for now this needs to be set to avoid generating a new one each time
