#######################################################################################
## Global Values

global:
  ## Database password
  ##
  databasePassword: kubeclarity

  ## Docker image
  ##
  docker:
    ## Configure registry
    ##
    registry: "ghcr.io/openclarity"
    tag: "v2.18.1"
    imagePullPolicy: Always

  ## Is this being installed under OpenShift restricted SCC?
  ## NOTE: You also need to set the PostgreSQL section correctly if using the OpenShift restricted SCC
  openShiftRestricted: false

## End of Global Values
#######################################################################################

#######################################################################################
## Curl Values
curl:
  image:
    registry: "docker.io"
    repository: curlimages/curl
    tag: 7.87.0
## End of Curl Values
#######################################################################################

#######################################################################################
## KubeClarity Values

kubeclarity:
  ## Docker Image values.
  docker:
    ## Use to overwrite the global docker params
    ##
    imageName: ""

  ## Logging level (debug, info, warning, error, fatal, panic).
  logLevel: warning

  enableDBInfoLog: false

  prometheus:
    enabled: false
    refreshIntervalSeconds: 300

  podAnnotations: {}

  service:
    type: ClusterIP
    annotations: {}

  ingress:
    # Be careful when using ingress. As there is no authentication on Kubeclarity yet, your instance may be accessible.
    # Make sure the ingress remains internal if you decide to enable it.
    enabled: false
    labels: {}
    annotations: {}

    # Optionally use ingressClassName instead of deprecated annotation.
    # See: https://kubernetes.io/docs/concepts/services-networking/ingress/#deprecated-annotation
    ingressClassName: ""

    hosts:
        # hostname you want to use
      - host: chart-example.local
        # paths will default to:
        # paths:
        #   - pathType: Prefix
        #     path: /
        paths: []

    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  ## In case of postgres refresh interval of refreshing materialized views in seconds
  # dbViewRefreshInterval: 5

  resources:
    requests:
      memory: "200Mi"
      cpu: "100m"
    limits:
      memory: "1000Mi"
      cpu: "1000m"

  initContainers:
    resources:
      requests:
        memory: "100Mi"
        cpu: "100m"
      limits:
        memory: "200Mi"
        cpu: "200m"

## End of KubeClarity Values
#######################################################################################

#######################################################################################
## KubeClarity Runtime Scan Values

kubeclarity-runtime-scan:
  httpsProxy: ""
  httpProxy: ""
  resultServicePort: 8888

  ## Scanner jobs and pods labels.
  labels:
    app: kubeclarity-scanner
    sidecar.istio.io/inject: "false"

  ## Scanner jobs namespace.
  # If left blank, the scanner jobs will run in the same namespace as pod being scanned.
  # If set, the scanner jobs will run in the given namespace unless:
  # 1. The scanner job must run in the pod namespace to fetch image pull secrets, OR
  # 2. The scanner job must run in the release namespace to fetch service credentials (more info in https://github.com/openclarity/kubeclarity#private-registries-support-for-k8s-runtime-scan)
  namespace: ""

  ## Scanner pods tolerations.
  # tolerations:
  # - key: key1
  #   operator: Exists
  #   effect: NoSchedule
  # - key: key1
  #   operator: Equal
  #   effect: NoSchedule
  #   value: "value1"

  ## Scanner pods nodeSelector.
  # nodeSelector:
  #   key1: value1

  registry:
    skipVerifyTlS: "false"
    useHTTP: "false"

  cis-docker-benchmark-scanner:
    ## Docker Image values.
    docker:
      ## Use to overwrite the global docker params
      ##
      imageName: ""

    ## Scanner logging level (debug, info, warning, error, fatal, panic).
    logLevel: warning

    ## Timeout for the cis docker benchmark scanner job.
    timeout: "2m"

    resources:
      requests:
        memory: "50Mi"
        cpu: "50m"
      limits:
        memory: "1000Mi"
        cpu: "1000m"

  vulnerability-scanner:
    ## Docker Image values.
    docker:
      ## Use to overwrite the global docker params
      ##
      imageName: ""

    ## Scanner logging level (debug, info, warning, error, fatal, panic).
    logLevel: warning

    resources:
      requests:
        memory: "50Mi"
        cpu: "50m"
      limits:
        memory: "1000Mi"
        cpu: "1000m"

    ## Analyzer config.
    analyzer:
      ## Space seperated list of analyzers. (syft gomod)
      analyzerList: "syft gomod"

      analyzerScope: "squashed"

      trivy:
        ## Enable trivy scanner, if true make sure to add it to analyzerList above
        ##
        enabled: false
        timeout: "300"

    ## Scanner config.
    scanner:
      ## Space seperated list of scanners. (grype dependency-track)
      scannerList: "grype"

      grype:
        ## Enable grype scanner, if true make sure to add it to scannerList above
        ##
        enabled: true
        ## Grype scanner mode. (LOCAL, REMOTE)
        mode: "REMOTE"

        ## Remote grype scanner config.
        remote-grype:
          timeout: "2m"

      dependency-track:
        ## Enable dependency-track scanner, if true make sure to add it to scannerList above
        ##
        enabled: false
        insecureSkipVerify: "true"
        disableTls: "true"
        apiserverAddress: "dependency-track-apiserver.dependency-track"
        apiKey: ""

      trivy:
        ## Enable trivy scanner, if true make sure to add it to scannerList above.
        ## To guarentee reliable scans, also ensure that the trivy analyzer is enabled.
        ##
        enabled: false
        timeout: "300"


## End of KubeClarity Runtime Scan Values
#######################################################################################

#######################################################################################
## KubeClarity Grype Server Values

kubeclarity-grype-server:
  enabled: true

  ## Docker Image values.
  docker:
    imageRepo: "ghcr.io/openclarity"
    imageTag: "v0.2.0"
    imagePullPolicy: Always

  ## Logging level (debug, info, warning, error, fatal, panic).
  logLevel: warning

  servicePort: 9991

  resources:
    requests:
      cpu: "200m"
      memory: "200Mi"
    limits:
      cpu: "1000m"
      memory: "1G"

## End of KubeClarity Grype Server Values
#######################################################################################

#######################################################################################
## KubeClarity Trivy Server Values
## https://github.com/aquasecurity/trivy/blob/main/helm/trivy/values.yaml

kubeclarity-trivy-server:
  enabled: false

  ## Docker Image values.
  image:
    registry: docker.io
    repository: aquasec/trivy
    tag: 0.41.0
    pullPolicy: IfNotPresent

  ## By default disable requirement for persistent storage
  persistence:
    enabled: false

  podSecurityContext:
    runAsUser: 1001
    runAsNonRoot: true
    fsGroup: 1001

  securityContext:
    privileged: false
    readOnlyRootFilesystem: true

  trivy:
    debugMode: false

  service:
    port: 9992

  resources:
    requests:
      cpu: "200m"
      memory: "200Mi"
    limits:
      cpu: "1000m"
      memory: "1G"

## End of KubeClarity Trivy Server Values
#######################################################################################

#######################################################################################
## KubeClarity SBOM DB Values

kubeclarity-sbom-db:
  ## Docker Image values.
  docker:
    ## Use to overwrite the global docker params
    ##
    imageName: ""

  ## Logging level (debug, info, warning, error, fatal, panic).
  logLevel: warning

  servicePort: 8080

  resources:
    requests:
      memory: "20Mi"
      cpu: "10m"
    limits:
      memory: "1Gi"
      cpu: "200m"

## End of KubeClarity SBOM DB Values
#######################################################################################

#######################################################################################
## KubeClarity Internal Postgres Values
## Use kubeclarity-postgresql if you want this chart to deploy a PostgreSQL instance
kubeclarity-postgresql:
  enabled: true

  ## Specify posgtresql image
  image:
    registry: docker.io
    repository: bitnami/postgresql
    tag: 14.6.0-debian-11-r31

  ## initdb parameters
  # initdb:
    ##  ConfigMap with scripts to be run at first boot
    ##  NOTE: This will override initdb.scripts
    # scriptsConfigMap
    ##  Secret with scripts to be run at first boot (in case it contains sensitive information)
    ##  NOTE: This can work along initdbScripts or initdbScriptsConfigMap
    # scriptsSecret:
    ## Specify the PostgreSQL username and password to execute the initdb scripts
    # user:
    # password:

  ## Setup database name and password
  auth:
    existingSecret: kubeclarity-postgresql-secret
    username: postgres
    database: kubeclarity

  service:
    ports:
      postgresql: 5432

  serviceAccount:
    enabled: true
  securityContext:
    # Default is true for K8s. Enabled needs to false for OpenShift restricted SCC and true for anyuid SCC
    enabled: true
    # fsGroup specification below is not applied if enabled=false. enabled=false is the required setting for OpenShift "restricted SCC" to work successfully.
    fsGroup: 1001
  containerSecurityContext:
    # Default is true for K8s. Enabled needs to false for OpenShift restricted SCC and true for anyuid SCC
    enabled: true
    # runAsUser specification below is not applied if enabled=false. enabled=false is the required setting for OpenShift "restricted SCC" to work successfully.
    runAsUser: 1001
    runAsNonRoot: true
  volumePermissions:
    # Default is true for K8s. Enabled needs to false for OpenShift restricted SCC and true for anyuid SCC
    enabled: false
    # if using restricted SCC set runAsUser: "auto" and if running under anyuid SCC - runAsUser needs to match the line above
    securityContext:
      runAsUser: 1001
  shmVolume:
    chmod:
      # if using restricted SCC with runAsUser: "auto" (above) then set shmVolume.chmod.enabled to false
      enabled: true

  primary:
    resources:
      requests:
        memory: "256Mi"
        cpu: "250m"
      limits:
        memory: "1000Mi"
        cpu: "1000m"

# End of KubeClarity Internal Postgres Values
#######################################################################################

# Use kubeclarity-postgresql-external if you want to reach an already existing PostgreSQL instance
kubeclarity-postgresql-external:
  enabled: false
  auth:
    existingSecret: kubeclarity-postgresql-secret
    username: kubeclarity
    host: pgsql.hostname  # replace this to reach your PostgreSQL instance
    port: 5432
    database: kubeclarity

# PostgreSQL connection information
kubeclarity-postgresql-secret:
  # Set create to true if you want this helm chart to create a secret holding pgsql password
  # based on global.databasePassword value
  # If create is set to false, a secret should already exist which has PostgreSQL
  # password under secretKey key
  create: true
  secretKey: "postgres-password"
