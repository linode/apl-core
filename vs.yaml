---
# Source: team-ns/templates/networkpolicy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-ingress-deny
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  podSelector: {}
  policyTypes:
    - Ingress
---
# Source: team-ns/templates/networkpolicy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-ingress-platform
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  # Match all Pods in this namespace
  podSelector: {}
  policyTypes:
    - Ingress
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              name: istio-system
    - from:
        - namespaceSelector:
            matchLabels:
              # FIXME: it seems that knative operator wipes out 'name' label,
              # we can still rely on automatic k8s labeling but it has some prerequsites: https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/#automatic-labelling
              # name: knative-serving
              kubernetes.io/metadata.name: knative-serving
    - from:
        - namespaceSelector:
            matchLabels:
              name: monitoring
          podSelector:
            matchLabels:
              app: prometheus
    # - from:
    #     - namespaceSelector:
    #         matchLabels:
    #           name: shared
---
# Source: team-ns/templates/networkpolicy.yaml
# Allow traffic from team's prometheus to team's alertmanager
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-to-alertmanager
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              name: team-demo
          podSelector:
            matchLabels:
              prometheus: demo-po-prometheus
  podSelector:
    matchLabels:
      alertmanager: demo-po-alertmanager
  policyTypes:
    - Ingress
---
# Source: team-ns/templates/networkpolicy.yaml
# Allow traffic from team's kube-state-metrics + team's alertmanager to team's prometheus
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-to-prometheus
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              name: team-demo
          podSelector:
            matchLabels:
              alertmanager: demo-po-alertmanager
        - namespaceSelector:
            matchLabels:
              name: team-demo
          podSelector:
            matchLabels:
              app.kubernetes.io/name: demo-po-grafana
  podSelector:
    matchLabels:
      prometheus: demo-po-prometheus
  policyTypes:
    - Ingress
---
# Source: team-ns/templates/networkpolicy.yaml
# Allow traffic from team's prometheus to team's kube-state-metrics
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: default-to-kube-state-metrics
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              name: team-demo
          podSelector:
            matchLabels:
              prometheus: demo-po-prometheus
  podSelector:
    matchLabels:
      app.kubernetes.io/name: kube-state-metrics
  policyTypes:
    - Ingress
---
# Source: team-ns/templates/networkpolicy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: hello-ingress-from-all-teams
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  podSelector:
    matchLabels:
      # The app label cannot be used because Knative appends revision number to the service
      serving.knative.dev/service: hello
  policyTypes:
    - Ingress
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              type: team
---
# Source: team-ns/templates/networkpolicy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: some-svc-ingress-from-all-teams
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  podSelector:
    matchLabels:
      otomi.io/app: some-svc
  policyTypes:
    - Ingress
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              type: team
---
# Source: team-ns/templates/networkpolicy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: service-a-ingress-allow-only
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  podSelector:
    matchLabels:
      otomi.io/app: service-a
  policyTypes:
    - Ingress
  ingress:
    - from:
        - namespaceSelector:
            matchLabels:
              name: team-team1
        - namespaceSelector:
            matchLabels:
              name: team-team2
          podSelector:
            matchLabels:
              otomi.io/app: service-x
        # An extra rule for Pods that are spawn by knative-serving
        - namespaceSelector:
            matchLabels:
              name: team-team2
          podSelector:
            matchLabels:
              serving.knative.dev/service: service-x
---
# Source: team-ns/templates/networkpolicy.yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: service-d-ingress-allow-only
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  podSelector:
    matchLabels:
      otomi.io/app: service-d
  policyTypes:
    - Ingress
---
# Source: team-ns/templates/quota.yaml
apiVersion: v1
kind: ResourceQuota
metadata:
  name: team-ns-quota
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  hard:
    pods: '50'
    services.loadbalancers: '1'
---
# Source: team-ns/templates/config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: team-ns-demo-tlspass-etc
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
data:
  nginx.conf: |
    events {
    }

    http {
      log_format main '$remote_addr - $remote_user [$time_local]  $status '
      '"$request" $body_bytes_sent "$http_referer" '
      '"$http_user_agent" "$http_x_forwarded_for"';
      access_log /var/log/nginx/access.log main;
      error_log  /var/log/nginx/error.log;

      server {
        listen 443 ssl;

        root /usr/share/nginx/html;
        index index.html;

        server_name tlspass.eks.dev.otomi.cloud;
        ssl_certificate /etc/nginx-server-certs/tls.crt;
        ssl_certificate_key /etc/nginx-server-certs/tls.key;
      }
    }
---
# Source: team-ns/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: ingress-update-team-demo
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: ingress-update
subjects:
  - kind: ServiceAccount
    name: default
    namespace: team-demo
---
# Source: team-ns/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: admin-team-demo
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: admin
subjects:
  - kind: ServiceAccount
    name: default
    namespace: team-demo
---
# Source: team-ns/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: unprivileged-team-demo
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: psp:unprivileged
subjects:
  - kind: ServiceAccount
    name: default
    namespace: team-demo
---
# Source: team-ns/templates/knative-services.yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: hello
  namespace: team-demo
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/minScale: '1'
    spec:
      containers:
        - image: otomi/nodejs-helloworld:v1.2.12
          env:
            - name: TARGET
              valueFrom:
                secretKeyRef:
                  name: mysecret-generic
                  key: TARGET
          resources:
            limits:
              cpu: 50m
              memory: 64Mi
            requests:
              cpu: 50m
              memory: 64Mi
---
# Source: team-ns/templates/knative-services.yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: hello-auth
  namespace: team-demo
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/minScale: '1'
    spec:
      containers:
        - image: otomi/nodejs-helloworld:v1.2.12
          env:
            - name: TARGET
              valueFrom:
                secretKeyRef:
                  name: mysecret-generic
                  key: TARGET
          resources:
            limits:
              cpu: 50m
              memory: 64Mi
            requests:
              cpu: 50m
              memory: 64Mi
          securityContext:
            runAsUser: 1002
---
# Source: team-ns/templates/knative-services.yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: tlspass
  namespace: team-demo
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  template:
    metadata:
      annotations:
        autoscaling.knative.dev/minScale: '1'
    spec:
      containers:
        - image: nginx:latest
          ports:
            - containerPort: 80
          resources:
            limits:
              cpu: 50m
              memory: 64Mi
            requests:
              cpu: 50m
              memory: 64Mi
          volumeMounts:
            - name: team-ns-demo-tlspass-etc
              mountPath: /etc
              readOnly: true
            - name: team-ns-demo-tlspass-etcnginxservercerts
              mountPath: /etc
              subPath: nginx-server-certs
              readOnly: true
      volumes:
        - name: team-ns-demo-tlspass-etc
          configMap:
            name: team-ns-demo-tlspass-etc
            items:
              - key: nginx.conf
                path: nginx.conf
        - name: team-ns-demo-tlspass-etcnginxservercerts
          secret:
            secretName: mysecret-tls
---
# Source: team-ns/templates/ingress.yaml
# ingress: public: tlspass (1)

# collect unique host and service names
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    externaldns: 'true'
    nginx.ingress.kubernetes.io/ssl-passthrough: 'true'
    # websocket upgrade snippet
    nginx.ingress.kubernetes.io/server-snippets: |
      location ~* /(ws(s)?|socket.io)/ {
          proxy_set_header Upgrade $http_upgrade;
          proxy_http_version 1.1;
          proxy_set_header X-Forwarded-Host $http_host;
          proxy_set_header X-Forwarded-Proto $scheme;
          proxy_set_header X-Forwarded-For $remote_addr;
          proxy_set_header Host $host;
          proxy_set_header Connection "upgrade";
          proxy_cache_bypass $http_upgrade;
        }
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
  name: nginx-team-demo-platform-public-tlspass
  namespace: istio-system
spec:
  ingressClassName: platform
  rules:
    - host: tlspass.team-demo.demo.eks.otomi.cloud
      http:
        paths:
          - backend:
              service:
                name: istio-ingressgateway-public
                port:
                  number: 443
            path: /
            pathType: Prefix
      # service tlspass, domain:
      # service tlspass, domain:

      # service alertmanager, domain:
      # service prometheus, domain:
---
# Source: team-ns/templates/ingress.yaml
# ingress: public: apps (2)

# collect unique host and service names
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    externaldns: 'true'
    # nginx.ingress.kubernetes.io/proxy-buffering: "off"
    # nginx.ingress.kubernetes.io/proxy-request-buffering: "off"
    ingress.kubernetes.io/ssl-redirect: 'true'
    nginx.ingress.kubernetes.io/upstream-vhost: $1.team-demo.demo.eks.otomi.cloud
    nginx.ingress.kubernetes.io/rewrite-target: /$3
    nginx.ingress.kubernetes.io/auth-response-headers: Authorization
    nginx.ingress.kubernetes.io/auth-url: 'http://oauth2-proxy.istio-system.svc.cluster.local/oauth2/auth'
    nginx.ingress.kubernetes.io/auth-signin: 'https://auth.demo.eks.otomi.cloud/oauth2/start?rd=/oauth2/redirect/$http_host$escaped_request_uri'
    # websocket upgrade snippet
    nginx.ingress.kubernetes.io/server-snippets: |
      location ~* /(ws(s)?|socket.io)/ {
          proxy_set_header Upgrade $http_upgrade;
          proxy_http_version 1.1;
          proxy_set_header X-Forwarded-Host $http_host;
          proxy_set_header X-Forwarded-Proto $scheme;
          proxy_set_header X-Forwarded-For $remote_addr;
          proxy_set_header Host $host;
          proxy_set_header Connection "upgrade";
          proxy_cache_bypass $http_upgrade;
        }
    nginx.ingress.kubernetes.io/configuration-snippet: |
      rewrite ^/$ https://otomi.demo.eks.otomi.cloud/ permanent;
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
  name: nginx-team-demo-platform-public-apps
  namespace: istio-system
spec:
  ingressClassName: platform
  rules:
    - host: apps.team-demo.demo.eks.otomi.cloud
      http:
        paths:
          - backend:
              service:
                name: istio-ingressgateway-public
                port:
                  number: 80
            path: /
            pathType: Prefix

          - backend:
              service:
                name: istio-ingressgateway-public
                port:
                  number: 80
            path: /(alertmanager|prometheus)(/|$)(.*)
            pathType: Prefix
  tls:
    - hosts:
        - apps.team-demo.demo.eks.otomi.cloud
      secretName: apps-team-demo-demo-eks-otomi-cloud
    # service alertmanager, domain:
    # service prometheus, domain:
    # service alertmanager, domain:
    # service prometheus, domain:

    # service hello, domain: hello.team-demo.demo.eks.otomi.cloud
---
# Source: team-ns/templates/ingress.yaml
# ingress: public: auth (1)

# collect unique host and service names
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    externaldns: 'true'
    # nginx.ingress.kubernetes.io/proxy-buffering: "off"
    # nginx.ingress.kubernetes.io/proxy-request-buffering: "off"
    ingress.kubernetes.io/ssl-redirect: 'true'
    nginx.ingress.kubernetes.io/auth-response-headers: Authorization
    nginx.ingress.kubernetes.io/auth-url: 'http://oauth2-proxy.istio-system.svc.cluster.local/oauth2/auth'
    nginx.ingress.kubernetes.io/auth-signin: 'https://auth.demo.eks.otomi.cloud/oauth2/start?rd=/oauth2/redirect/$http_host$escaped_request_uri'
    # websocket upgrade snippet
    nginx.ingress.kubernetes.io/server-snippets: |
      location ~* /(ws(s)?|socket.io)/ {
          proxy_set_header Upgrade $http_upgrade;
          proxy_http_version 1.1;
          proxy_set_header X-Forwarded-Host $http_host;
          proxy_set_header X-Forwarded-Proto $scheme;
          proxy_set_header X-Forwarded-For $remote_addr;
          proxy_set_header Host $host;
          proxy_set_header Connection "upgrade";
          proxy_cache_bypass $http_upgrade;
        }
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
  name: nginx-team-demo-platform-public-auth
  namespace: istio-system
spec:
  ingressClassName: platform
  rules:
    - host: hello.team-demo.demo.eks.otomi.cloud
      http:
        paths:
          - backend:
              service:
                name: istio-ingressgateway-public
                port:
                  number: 80
            path: /
            pathType: Prefix
  tls:
    - hosts:
        - hello.team-demo.demo.eks.otomi.cloud
      secretName: hello-team-demo-demo-eks-otomi-cloud
    # service hello, domain: hello.team-demo.demo.eks.otomi.cloud
    # service hello, domain: hello.team-demo.demo.eks.otomi.cloud

    # service grafana, domain:
---
# Source: team-ns/templates/ingress.yaml
# ingress: public: auth-forward (1)

# collect unique host and service names
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    externaldns: 'true'
    # nginx.ingress.kubernetes.io/proxy-buffering: "off"
    # nginx.ingress.kubernetes.io/proxy-request-buffering: "off"
    ingress.kubernetes.io/ssl-redirect: 'true'
    nginx.ingress.kubernetes.io/auth-response-headers: Authorization
    nginx.ingress.kubernetes.io/auth-url: 'http://oauth2-proxy.istio-system.svc.cluster.local/oauth2/auth'
    nginx.ingress.kubernetes.io/auth-signin: 'https://auth.demo.eks.otomi.cloud/oauth2/start?rd=/oauth2/redirect/$http_host$escaped_request_uri'
    # websocket upgrade snippet
    nginx.ingress.kubernetes.io/server-snippets: |
      location ~* /(ws(s)?|socket.io)/ {
          proxy_set_header Upgrade $http_upgrade;
          proxy_http_version 1.1;
          proxy_set_header X-Forwarded-Host $http_host;
          proxy_set_header X-Forwarded-Proto $scheme;
          proxy_set_header X-Forwarded-For $remote_addr;
          proxy_set_header Host $host;
          proxy_set_header Connection "upgrade";
          proxy_cache_bypass $http_upgrade;
        }
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
  name: nginx-team-demo-platform-public-auth-forward
  namespace: istio-system
spec:
  ingressClassName: platform
  rules:
    - host: grafana.team-demo.demo.eks.otomi.cloud
      http:
        paths:
          - backend:
              service:
                name: istio-ingressgateway-public
                port:
                  number: 80
            path: /
            pathType: Prefix
  tls:
    - hosts:
        - grafana.team-demo.demo.eks.otomi.cloud
      secretName: grafana-team-demo-demo-eks-otomi-cloud
    # service grafana, domain:
    # service grafana, domain:

    # service hello-auth, domain: tlspass.eks.dev.otomi.cloud
    # service has-cert-svc, domain:
    # service service-e, domain:
---
# Source: team-ns/templates/ingress.yaml
# ingress: public: open (3)

# collect unique host and service names
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    externaldns: 'true'
    # nginx.ingress.kubernetes.io/proxy-buffering: "off"
    # nginx.ingress.kubernetes.io/proxy-request-buffering: "off"
    ingress.kubernetes.io/ssl-redirect: 'true'
    # websocket upgrade snippet
    nginx.ingress.kubernetes.io/server-snippets: |
      location ~* /(ws(s)?|socket.io)/ {
          proxy_set_header Upgrade $http_upgrade;
          proxy_http_version 1.1;
          proxy_set_header X-Forwarded-Host $http_host;
          proxy_set_header X-Forwarded-Proto $scheme;
          proxy_set_header X-Forwarded-For $remote_addr;
          proxy_set_header Host $host;
          proxy_set_header Connection "upgrade";
          proxy_cache_bypass $http_upgrade;
        }
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
  name: nginx-team-demo-platform-public-open
  namespace: istio-system
spec:
  ingressClassName: platform
  rules:
    - host: has-cert-svc.team-demo.demo.eks.otomi.cloud
      http:
        paths:
          - backend:
              service:
                name: istio-ingressgateway-public
                port:
                  number: 80
            path: /jeho
            pathType: Prefix
    - host: tlspass.eks.dev.otomi.cloud
      http:
        paths:
          - backend:
              service:
                name: istio-ingressgateway-public
                port:
                  number: 80
            path: /
            pathType: Prefix
  tls:
    - hosts:
        - has-cert-svc.team-demo.demo.eks.otomi.cloud
      secretName: has-cert-svc-team-demo-demo-eks-otomi-cloud
    - hosts:
        - tlspass.eks.dev.otomi.cloud
      secretName: tlspass-eks-dev-otomi-cloud
    # service hello-auth, domain: tlspass.eks.dev.otomi.cloud
    # service has-cert-svc, domain:
    # service service-e, domain:
    # service hello-auth, domain: tlspass.eks.dev.otomi.cloud
    # service has-cert-svc, domain:
    # service service-e, domain:
---
# Source: team-ns/templates/ingress.yaml
# ingress: public: open (3)

# collect unique host and service names
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  annotations:
    externaldns: 'true'
    # nginx.ingress.kubernetes.io/proxy-buffering: "off"
    # nginx.ingress.kubernetes.io/proxy-request-buffering: "off"
    ingress.kubernetes.io/ssl-redirect: 'true'
    nginx.ingress.kubernetes.io/whitelist-source-range: '10.0.0.0/24'
    # websocket upgrade snippet
    nginx.ingress.kubernetes.io/server-snippets: |
      location ~* /(ws(s)?|socket.io)/ {
          proxy_set_header Upgrade $http_upgrade;
          proxy_http_version 1.1;
          proxy_set_header X-Forwarded-Host $http_host;
          proxy_set_header X-Forwarded-Proto $scheme;
          proxy_set_header X-Forwarded-For $remote_addr;
          proxy_set_header Host $host;
          proxy_set_header Connection "upgrade";
          proxy_cache_bypass $http_upgrade;
        }
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
  name: nginx-team-demo-net-a-public-open
  namespace: istio-system
spec:
  ingressClassName: net-a
  rules:
    - host: service-e.team-demo.demo.eks.otomi.cloud
      http:
        paths:
          - backend:
              service:
                name: istio-ingressgateway-public
                port:
                  number: 80
            path: /
            pathType: Prefix
  tls:
    - hosts:
        - service-e.team-demo.demo.eks.otomi.cloud
      secretName: service-e-team-demo-demo-eks-otomi-cloud
---
# Source: team-ns/templates/ingress.yaml
# split list of services into separate ingress types:
# - core apps that need path forwarding (apps.*/appName stuff)
# - public/private?
# - auth/open?
# - tlsPass?

# service tlspass, domain:
---
# Source: team-ns/templates/argocd/argocd-project.yaml
apiVersion: argoproj.io/v1alpha1
kind: AppProject
metadata:
  name: team-demo
  namespace: argocd
  # Finalizer that ensures that project is not deleted until it is not referenced by any application
  finalizers:
    - resources-finalizer.argocd.argoproj.io
spec:
  description: ArgoCD project for team demo
  # Allow manifests to deploy from any Git repos
  sourceRepos:
    - https://gitea.demo.eks.otomi.cloud/otomi/team-demo-argocd.git
  # Only permit applications to deploy to the guestbook namespace in the same cluster
  destinations:
    - namespace: team-demo
      server: https://kubernetes.default.svc
  # Deny all cluster-scoped resources from being created
  clusterResourceWhitelist: []
  # - group: ''
  #   kind: Namespace
  # Allow all namespaced-scoped resources to be created, except for ResourceQuota, LimitRange, NetworkPolicy
  namespaceResourceBlacklist:
    - group: ''
      kind: ResourceQuota
    - group: ''
      kind: LimitRange
    - group: ''
      kind: NetworkPolicy
    - group: networking.istio.io
      kind: VirtualService
    - group: networking.istio.io
      kind: Sidecar
    - group: networking.istio.io
      kind: Gateway
  # Deny all namespaced-scoped resources from being created
  # namespaceResourceWhitelist: []
  # - group: 'apps'
  #   kind: Deployment
  # - group: 'apps'
  #   kind: StatefulSet
  roles:
    # we create a scoped team-admin role since we are only allowed access to team-* projects as team-admin in multitenant setup
    - name: team-admin
      description: Team member privileges to team-demo
      policies:
        - p, proj:team-demo:team-admin, *, *, team-demo/*, allow
      groups:
        - team-admin
        - team-demo
    - name: team-member
      description: Team member privileges to team-demo
      policies:
        - p, proj:team-demo:team-member, *, get, team-demo/*, allow
      groups:
        - team-demo
    # A role which provides read-only access to all applications in the project
    - name: read-only
      description: Read-only privileges to team-demo
      policies:
        - p, proj:team-demo:read-only, applications, get, team-demo/*, allow
      groups:
        - team-viewer
    - name: ci-role
      description: Sync privileges for team applications
      policies:
        - p, proj:team-demo:ci-role, applications, sync, team-demo/*, allow
      # NOTE: JWT tokens can only be generated by the API server and the token is not persisted
      # anywhere by Argo CD. It can be prematurely revoked by removing the entry from this list.
      jwtTokens:
        - iat: 1535390316
---
# Source: team-ns/templates/argocd/argocd-application.yaml
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: team-demo
  namespace: argocd
spec:
  project: team-demo
  source:
    repoURL: https://gitea.demo.eks.otomi.cloud/otomi/team-demo-argocd.git
    targetRevision: HEAD
    path: ./
  destination:
    server: https://kubernetes.default.svc
    namespace: team-demo
---
# Source: team-ns/templates/external-secrets.yaml
apiVersion: kubernetes-client.io/v1
kind: ExternalSecret
metadata:
  name: mysecret-generic
  namespace: team-demo
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  backendType: vault
  vaultMountPoint: kubernetes
  vaultRole: default
  template:
    type: Opaque
  data:
    - key: '/secret/data/teams/team-demo/mysecret-generic'
      name: TARGET
      property: TARGET
---
# Source: team-ns/templates/external-secrets.yaml
apiVersion: kubernetes-client.io/v1
kind: ExternalSecret
metadata:
  name: mysecret-registry
  namespace: team-demo
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  backendType: vault
  vaultMountPoint: kubernetes
  vaultRole: default
  template:
    type: kubernetes.io/dockerconfigjson
  data:
    - key: '/secret/data/teams/team-demo/mysecret-registry'
      name: '.dockerconfigjson'
---
# Source: team-ns/templates/external-secrets.yaml
apiVersion: kubernetes-client.io/v1
kind: ExternalSecret
metadata:
  name: mysecret-tls
  namespace: team-demo
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  backendType: vault
  vaultMountPoint: kubernetes
  vaultRole: default
  template:
    type: kubernetes.io/tls
  data:
    - key: '/secret/data/teams/team-demo/mysecret-tls'
      property: tls.crt
      name: tls.crt
    - key: '/secret/data/teams/team-demo/mysecret-tls'
      property: tls.key
      name: tls.key
    - key: '/secret/data/teams/team-demo/mysecret-tls'
      property: ca.crt
      name: ca.crt
---
# Source: team-ns/templates/istio-gateway.yaml
# collect unique domains for this GW
apiVersion: networking.istio.io/v1beta1
kind: Gateway
metadata:
  name: team-demo-private-tlspass
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  selector:
    istio: ingressgateway-private
  servers:
    - hosts:
        - 'team-demo/*.team-demo.demo.eks.otomi.cloud'
      tls:
        mode: PASSTHROUGH
      port:
        number: 443
        name: https
        protocol: HTTPS
---
# Source: team-ns/templates/istio-gateway.yaml
apiVersion: networking.istio.io/v1beta1
kind: Gateway
metadata:
  name: team-demo-private-tlsterm
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  selector:
    istio: ingressgateway-private
  servers:
    - hosts:
        - 'team-demo/*.team-demo.demo.eks.otomi.cloud'
      port:
        name: http
        number: 80
        protocol: HTTP
---
# Source: team-ns/templates/istio-gateway.yaml
apiVersion: networking.istio.io/v1beta1
kind: Gateway
metadata:
  name: team-demo-public-tlspass
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  selector:
    istio: ingressgateway-public
  servers:
    - hosts:
        - 'team-demo/*.team-demo.demo.eks.otomi.cloud'
      tls:
        mode: PASSTHROUGH
      port:
        number: 443
        name: https
        protocol: HTTPS
---
# Source: team-ns/templates/istio-gateway.yaml
apiVersion: networking.istio.io/v1beta1
kind: Gateway
metadata:
  name: team-demo-public-tlsterm
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  selector:
    istio: ingressgateway-public
  servers:
    - hosts:
        - 'team-demo/*.team-demo.demo.eks.otomi.cloud'
      port:
        name: http
        number: 80
        protocol: HTTP
---
# Source: team-ns/templates/istio-sidecar.yaml
apiVersion: monitoring.coreos.com/v1
kind: PodMonitor
metadata:
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
    prometheus: team-demo
  name: istio-sidecars
spec:
  namespaceSelector:
    matchNames: [team-demo]
  podMetricsEndpoints:
    - path: /stats/prometheus
      port: http-envoy-prom
  selector:
    matchLabels:
      security.istio.io/tlsMode: istio
---
# Source: team-ns/templates/istio-serviceentry.yaml
apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: demo-service-a-domain1-com
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  hosts:
    - domain1.com
  ports:
    - number: 8443
      name: tcp-8443
      protocol: TCP
  exportTo:
    - '.'
  location: MESH_EXTERNAL
  resolution: DNS
---
# Source: team-ns/templates/istio-serviceentry.yaml
apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: demo-service-a-domain2-com
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  hosts:
    - domain2.com
  ports:
    - number: 443
      name: https-443
      protocol: HTTPS
  exportTo:
    - '.'
  location: MESH_EXTERNAL
  resolution: DNS
---
# Source: team-ns/templates/istio-serviceentry.yaml
apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: demo-service-a-185-199-110-153
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  hosts:
    - 185-199-110-153 # not used but still mandatory
  addresses:
    - '185.199.110.153'
  ports:
    - number: 443
      name: tcp-443
      protocol: TCP
  resolution: STATIC
  location: MESH_EXTERNAL
  endpoints:
    - address: '185.199.110.153'
  exportTo:
    - '.'
---
# Source: team-ns/templates/istio-serviceentry.yaml
apiVersion: networking.istio.io/v1alpha3
kind: ServiceEntry
metadata:
  name: demo-service-a-ae-1
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  hosts:
    - ae-1 # not used but still mandatory
  addresses:
    - 'ae::1'
  ports:
    - number: 443
      name: tcp-443
      protocol: TCP
  resolution: STATIC
  location: MESH_EXTERNAL
  endpoints:
    - address: 'ae::1'
  exportTo:
    - '.'
---
# Source: team-ns/templates/istio-sidecar.yaml
apiVersion: networking.istio.io/v1beta1
kind: Sidecar
metadata:
  name: default
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  outboundTrafficPolicy:
    mode: REGISTRY_ONLY
---
# Source: team-ns/templates/istio-virtualservices.yaml
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: alertmanager-teamdemo-demo-eks-otomi-cloud
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
    auth: 'true'
spec:
  gateways:
    - team-demo/team-demo-public-tlsterm
  hosts:
    - alertmanager.team-demo.demo.eks.otomi.cloud
  http:
    - match:
        - uri:
            prefix: /logout-otomi
      redirect:
        authority: auth.demo.eks.otomi.cloud
        uri: /oauth2/sign_out?rd=https://keycloak.demo.eks.otomi.cloud/realms/otomi/protocol/openid-connect/logout?redirect_uri=https://otomi.demo.eks.otomi.cloud
    - match:
        - uri:
            prefix: '/'
      rewrite:
        uri: /
      route:
        - destination:
            host: demo-po-alertmanager.team-demo.svc.cluster.local
            port:
              number: 9093
          headers:
            request:
              set:
                # fix for istio (=envoy) incorrectly setting proto to http
                # (@see https://github.com/istio/istio/issues/7964):
                X-Forwarded-Proto: https
---
# Source: team-ns/templates/istio-virtualservices.yaml
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: grafana-teamdemo-demo-eks-otomi-cloud
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
    auth: 'true'
spec:
  gateways:
    - team-demo/team-demo-public-tlsterm
  hosts:
    - grafana.team-demo.demo.eks.otomi.cloud
  http:
    - match:
        - uri:
            prefix: /logout-otomi
      redirect:
        authority: auth.demo.eks.otomi.cloud
        uri: /oauth2/sign_out?rd=https://keycloak.demo.eks.otomi.cloud/realms/otomi/protocol/openid-connect/logout?redirect_uri=https://otomi.demo.eks.otomi.cloud
    - match:
        - uri:
            prefix: '/'
      route:
        - destination:
            host: demo-po-grafana.team-demo.svc.cluster.local
            port:
              number: 80
          headers:
            request:
              set:
                # fix for istio (=envoy) incorrectly setting proto to http
                # (@see https://github.com/istio/istio/issues/7964):
                X-Forwarded-Proto: https
              remove:
                - authorization
---
# Source: team-ns/templates/istio-virtualservices.yaml
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: prometheus-teamdemo-demo-eks-otomi-cloud
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
    auth: 'true'
spec:
  gateways:
    - team-demo/team-demo-public-tlsterm
  hosts:
    - prometheus.team-demo.demo.eks.otomi.cloud
  http:
    - match:
        - uri:
            prefix: /logout-otomi
      redirect:
        authority: auth.demo.eks.otomi.cloud
        uri: /oauth2/sign_out?rd=https://keycloak.demo.eks.otomi.cloud/realms/otomi/protocol/openid-connect/logout?redirect_uri=https://otomi.demo.eks.otomi.cloud
    - match:
        - uri:
            prefix: '/'
      rewrite:
        uri: /
      route:
        - destination:
            host: demo-po-prometheus.team-demo.svc.cluster.local
            port:
              number: 9090
          headers:
            request:
              set:
                # fix for istio (=envoy) incorrectly setting proto to http
                # (@see https://github.com/istio/istio/issues/7964):
                X-Forwarded-Proto: https
---
# Source: team-ns/templates/istio-virtualservices.yaml
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: tlspass-eks-dev-otomi-cloud
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  gateways:
    - knative-serving/knative-ingress-gateway
  hosts:
    - tlspass.eks.dev.otomi.cloud
  http:
    - match:
        - uri:
            prefix: /logout-otomi
      redirect:
        authority: auth.demo.eks.otomi.cloud
        uri: /oauth2/sign_out?rd=https://keycloak.demo.eks.otomi.cloud/realms/otomi/protocol/openid-connect/logout?redirect_uri=https://otomi.demo.eks.otomi.cloud
    - match:
        - uri:
            prefix: '/'
      rewrite:
        authority: hello-auth.team-demo.demo.eks.otomi.cloud
        uri: /
      route:
        - destination:
            host: istio-ingressgateway-public.istio-system.svc.cluster.local
            port:
              number: 80
          headers:
            request:
              set:
                # fix for istio (=envoy) incorrectly setting proto to http
                # (@see https://github.com/istio/istio/issues/7964):
                X-Forwarded-Proto: https
---
# Source: team-ns/templates/istio-virtualservices.yaml
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: hascertsvc-teamdemo-demo-eks-otomi-cloudjeho
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  gateways:
    - team-demo/team-demo-public-tlsterm
  hosts:
    - has-cert-svc.team-demo.demo.eks.otomi.cloud
  http:
    - match:
        - uri:
            prefix: /logout-otomi
      redirect:
        authority: auth.demo.eks.otomi.cloud
        uri: /oauth2/sign_out?rd=https://keycloak.demo.eks.otomi.cloud/realms/otomi/protocol/openid-connect/logout?redirect_uri=https://otomi.demo.eks.otomi.cloud
    - match:
        - uri:
            prefix: '/jeho'
      rewrite:
        uri: /
      route:
        - destination:
            host: has-cert-svc.team-demo.svc.cluster.local
            port:
              number: 80
          headers:
            request:
              set:
                # fix for istio (=envoy) incorrectly setting proto to http
                # (@see https://github.com/istio/istio/issues/7964):
                X-Forwarded-Proto: https
---
# Source: team-ns/templates/istio-virtualservices.yaml
apiVersion: networking.istio.io/v1beta1
kind: VirtualService
metadata:
  name: servicee-teamdemo-demo-eks-otomi-cloud
  labels:
    app: team-ns
    app.kubernetes.io/name: team-ns
    app.kubernetes.io/instance: 'team-ns-demo'
    app.kubernetes.io/managed-by: 'Helm'
    app.kubernetes.io/version: 0.1.0
    app.kubernetes.io/part-of: otomi
    helm.sh/chart: 'team-ns-0.1.0'
    otomi.io/team: demo
spec:
  gateways:
    - team-demo/team-demo-public-tlsterm
  hosts:
    - service-e.team-demo.demo.eks.otomi.cloud
  http:
    - match:
        - uri:
            prefix: /logout-otomi
      redirect:
        authority: auth.demo.eks.otomi.cloud
        uri: /oauth2/sign_out?rd=https://keycloak.demo.eks.otomi.cloud/realms/otomi/protocol/openid-connect/logout?redirect_uri=https://otomi.demo.eks.otomi.cloud
    - match:
        - uri:
            prefix: '/'
      rewrite:
        uri: /
      route:
        - destination:
            host: service-e.team-demo.svc.cluster.local
            port:
              number: 80
          headers:
            request:
              set:
                # fix for istio (=envoy) incorrectly setting proto to http
                # (@see https://github.com/istio/istio/issues/7964):
                X-Forwarded-Proto: https
            response:
              set:
                X-Frame-Options: same-origin
                sander: same-origin
