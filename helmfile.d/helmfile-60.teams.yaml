bases:
  - snippets/defaults.gotmpl
---
{{- $v := .Environment.Values }}
{{- $tc := $v.teamConfig }}
{{- $coreTeamServices := list }}{{- range $s := $tc.services }}{{ $coreTeamServices = append $coreTeamServices (merge $s (dict "isCore" true)) }}{{ end }}
{{- $c := $v.charts }}
{{- $cm := index $v.charts "cert-manager" }}
{{- $po := index $v.charts "prometheus-operator" }}
{{- $slackTpl := tpl (readFile "../values/prometheus-operator/slack-configs.gotmpl") $v | toString }}
releases:
  {{- range $teamId, $team := $tc.teams }}
  {{- if hasKey $team "services" }}
  {{- $domain := printf "%s%s.%s" $v.otomi.teamPrefix $teamId $v.cluster.domain }}
  {{- $appsDomain := printf "apps.%s" $domain }}
  {{- $azure := $team | get "azure" dict }}
  - name: team-ns-{{ $teamId }}
    installed: true
    namespace: team-{{ $teamId }}
    chart: ../charts/team-ns
    labels:
      tag: teams
      team: {{ $teamId }}
    values:
      - cluster: {{- $v.cluster | toYaml | nindent 10 }}
        otomi: {{- $v.otomi | toYaml | nindent 10 }}
        domain: {{ $domain }}
        certStage: {{ $cm.stage }}
        knative:
          enabled: true
      - {{- $team | toYaml | nindent 8 }}
        teamId: {{ $teamId }}
      - services: {{- concat $coreTeamServices ($team | get "services" list) | toYaml | nindent 10 }}
        {{- if $v.otomi.isMultitenant }}
        {{- if ($team | get "cicd.enabled" "false") }}
        {{- $cicdFlavour := ($team | get "cicd.type" "drone") }}
        {{- if eq $cicdFlavour "drone" }}
        # TODO: fix this weirdness: the next two lines fook the yaml parser:
        # - name: drone
        #   svc: drone-{{ $teamId }}
        {{- end }}
        {{- end }}
        {{- if ne (len ($team | get "sites" list)) 0 }}
        - name: blackbox
          svc: prometheus-blackbox-exporter
          port: 9115
        {{- end }}
        {{- end }}
  {{- if $v.otomi.isMultitenant }}        
  - name: prometheus-{{ $teamId }}
    installed: true
    namespace: team-{{ $teamId }}
    chart: ../charts/prometheus-operator
    labels:
      tag: teams
      team: {{ $teamId }}
    values:
      - ../values/prometheus-operator/prometheus-operator.gotmpl
      - ../values/prometheus-operator/prometheus-operator-team.gotmpl
      - nameOverride: {{ $teamId }}-po
        fullnameOverride: {{ $teamId }}-po
        alertmanager:
          alertmanagerSpec:
            externalUrl: https://{{ $appsDomain }}/alertmanager
          config:
            {{- $receiver := ($team | get "receiver" ($po.alertmanager | get "receiver" "slack")) }}
            {{- if eq $receiver "slack" }}
            global:
              slack_api_url: {{ $team | get "slack.url" ($po.alertmanager | get "slack.url" $v.redkubesSlackUrl) }}
            {{- end }}
            receivers:
              - name: "null"
              {{- $channel := $team | get "slack.channel" "mon-otomi" }}
              {{- if eq $receiver "slack" }}
              - name: default
                slack_configs:
                  - channel: "#{{ $team | get "slack.channel" "mon-otomi" }}"
                    {{- $slackTpl | nindent 20 }}
              - name: critical
                slack_configs:
                  - channel: "#{{ $team | get "slack.channel" "mon-otomi" }}-crit"
                    {{- $slackTpl | nindent 20 }}
              {{- else }}
              {{ $suffix := (hasKey $team "receiver") | ternary "" ".monitoring.svc.cluster.local" }}
              - name: default
                webhook_configs:
                  - url: "http://prometheus-msteams{{ $suffix }}:2000/low_priority_channel"
                    send_resolved: true
              - name: critical
                webhook_configs:
                  - url: "http://prometheus-msteams{{ $suffix }}:2000/high_priority_channel"
                    send_resolved: true
              {{- end }}
              - name: critical-redkubes
              {{- if and $v.otomi.isRedkubesMonitored (hasKey $team "receiver") }}
                # sending team criticals also to redkubes to be aware of team issues
                slack_configs:
                  - channel: "#{{ $channel }}-crit"
                    api_url: {{ $v.redkubesSlackUrl }}
                    {{- $slackTpl | nindent 20 }}
              {{- end }}
        commonLabels:
          prometheus: team-{{ $teamId }}
        prometheus:
          prometheusSpec:
            serviceMonitorSelector:
              matchLabels:
                prometheus: team-{{ $teamId }}
            externalUrl: https://{{ $appsDomain }}/prometheus
            ruleNamespaceSelector:
              matchLabels:
                name: team-{{ $teamId }}
            podMonitorNamespaceSelector:
              matchLabels:
                name: team-{{ $teamId }}
            serviceMonitorNamespaceSelector:
              matchLabels:
                name: team-{{ $teamId }}
            additionalScrapeConfigs:
              - job_name: probe-services-{{ $teamId }}
                metrics_path: /probe
                scrape_interval: 10m
                params:
                  module: [http_2xx]  # Look for a HTTP 200 response.
                static_configs:
                  - targets:
                    {{ $registry := list }}
                    {{- range $s := $team.services }}
                    {{- if and (hasKey $s "isPublic") (not ($s | get "ksvc.scaleToZero" false)) }}
                    {{- $svcDomain := ($s | get "domain" (printf "%s.%s" $s.name $domain)) }}
                    {{- $path := "/" }}{{ if hasKey $s "paths" }}{{ $path = index $s.paths 0 }}{{ end }}
                    {{- $url := printf "%s%s" $svcDomain $path }}
                    {{- if not (has $url $registry) }}
                    {{- $registry = append $registry $url }}
                    - https://{{ $url }}
                    {{- end }}
                    {{- end }}
                    {{- end }}
                relabel_configs:
                  - source_labels: [__address__]
                    target_label: __param_target
                  - source_labels: [__param_target]
                    target_label: instance
                  - target_label: __address__
                    replacement: prometheus-blackbox-exporter.monitoring:9115
        additionalPrometheusRules:
          - name: blackbox
            {{- readFile "../values/prometheus-operator/rules/blackbox.yaml" | nindent 12 }}
        grafana:
          nameOverride: {{ $teamId }}-po-grafana
          fullnameOverride: {{ $teamId }}-po-grafana
          grafana.ini:
            server:
              root_url: https://{{ $appsDomain }}/grafana
            {{- if ($team | get "oidc.custom" false) }}
            "auth.generic_oauth":
              client_id: {{ $team.oidc.clientID }}
              client_secret: {{ $team.oidc.clientSecret }}
            {{- end }}
          additionalDataSources:
            - name: Prometheus-admin
              editable: false
              type: prometheus
              access: proxy
              url: http://po-prometheus.monitoring:9090
            - name: Prometheus-Istio
              editable: false
              type: prometheus
              access: proxy
              url: http://prometheus.istio-system:9090
            - name: Loki
              editable: false
              type: loki
              access: proxy
              url: http://loki.monitoring:11811
              basicAuth: true
              basicAuthUser: {{ $teamId }}
              basicAuthPassword: {{ $team.password }}
            {{- if $c.sitespeed.enabled }}
            - name: Graphite
              editable: false
              type: graphite
              access: proxy
              url: http://graphite.monitoring:80
            {{- end }}
            {{- if and (eq $v.cluster.provider "azure") ($team | get "azure.monitor" false) }}
            {{- $monitor := (($team | get "azure.monitor.useAdmin" false) | ternary ($v.azure | getOrNil "monitor") ($team | getOrNil "azure.monitor")) }}
            {{- with $monitor }}
            - name: Azure Monitor
              type: grafana-azure-monitor-datasource
              access: proxy
              jsonData:
                cloudName: azuremonitor
                subscriptionId: {{ $v.azure.subscriptionId }}
                tenantId: {{ $v.azure.tenantId }}
                clientId: {{ .clientId }}
                logAnalyticsTenantId: {{ . | get "logAnalyticsTenantId" $v.azure.tenantId }}
                logAnalyticsClientId: {{ . | get "logAnalyticsClientId" .clientId }}
                logAnalyticsDefaultWorkspace: {{ .logAnalyticsWorkspace }}
                appInsightsAppId: {{ . | get "appInsightsAppId" .clientId }}
                azureLogAnalyticsSameAs: true
                keepCookies: []
              secureJsonData:
                clientSecret: {{ .clientSecret }}
                logAnalyticsClientSecret: {{ . | get "logAnalyticsClientSecret" .clientSecret }}
                appInsightsAppSecret : {{ . | get "appInsightsAppSecret" .clientSecret }}
              version: 4
              editable: false
            {{- end }}
            {{- end }}
  {{ if eq ($team | get "receiver" "slack") "msteams" }}
  - name: prometheus-msteams-{{ $teamId }}
    installed: true
    namespace: team-{{ $teamId }}
    chart: ../charts/prometheus-msteams
    labels:
      tag: teams
      team: {{ $teamId }}
    values:
      - ../values/prometheus-msteams/prometheus-msteams.gotmpl
      - commonLabels:
          team: {{ $teamId }}
        metrics:
          serviceMonitor:
            additionalLabels:
              release: prometheus-{{ $teamId }}
        connectors:
          - high_priority_channel: {{ $team | get "msteams.highPrio" ($po | get "alertmanager.msteams.highPrio") }}
          - low_priority_channel: {{ $team | get "msteams.lowPrio" ($po | get "alertmanager.msteams.lowPrio") }}
  {{- end }}

  - name: grafana-dashboards-{{ $teamId }}
    installed: true
    namespace: team-{{ $teamId }}
    chart: ../charts/grafana-dashboards
    labels:
      tag: teams
      team: {{ $teamId }}
    values:
      - ../values/grafana-dashboards/grafana-dashboards.gotmpl
      - cluster: {{- $v.cluster | toYaml | nindent 10 }}
        team: {{ $teamId }}
        folders:
          - k8s
          - istio
          {{- if and (eq $v.cluster.provider "azure") (hasKey $azure "monitor") }}
          - azure{{ end }}
          {{- if $team | get "stack.sitespeed" false }}
          - sitespeed{{ end }}
  {{- end }}
  {{- end }}
  {{- end }}
