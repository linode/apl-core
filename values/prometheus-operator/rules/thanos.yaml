groups:
  - name: thanos-compact
    rules:
      - alert: ThanosCompactMultipleRunning
        annotations:
          description: No more than one Thanos Compact instance should be running at once.
            There are {{$value}} instances running.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanoscompactmultiplerunning
          summary: Thanos Compact has multiple instances running.
        expr: sum by (cluster, job) (up{job=~".*thanos-receiver-compact.*"}) > 1
        for: 5m
        labels:
          severity: warning
      - alert: ThanosCompactHalted
        annotations:
          description: Thanos Compact {{$labels.job}} has failed to run and now is halted.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanoscompacthalted
          summary: Thanos Compact has failed to run and is now halted.
        expr: thanos_compact_halted{job=~".*thanos-receiver-compact.*"} == 1
        for: 5m
        labels:
          severity: warning
      - alert: ThanosCompactHighCompactionFailures
        annotations:
          description: Thanos Compact {{$labels.job}} is failing to execute {{$value |
            humanize}}% of compactions.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanoscompacthighcompactionfailures
          summary: Thanos Compact is failing to execute compactions.
        expr: |
          (
            sum by (cluster, job) (rate(thanos_compact_group_compactions_failures_total{job=~".*thanos-receiver-compact.*"}[5m]))
          /
            sum by (cluster, job) (rate(thanos_compact_group_compactions_total{job=~".*thanos-receiver-compact.*"}[5m]))
          * 100 > 5
          )
        for: 15m
        labels:
          severity: warning
      - alert: ThanosCompactBucketHighOperationFailures
        annotations:
          description: Thanos Compact {{$labels.job}} Bucket is failing to execute {{$value
            | humanize}}% of operations.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanoscompactbuckethighoperationfailures
          summary: Thanos Compact Bucket is having a high number of operation failures.
        expr: |
          (
            sum by (cluster, job) (rate(thanos_objstore_bucket_operation_failures_total{job=~".*thanos-receiver-compact.*"}[5m]))
          /
            sum by (cluster, job) (rate(thanos_objstore_bucket_operations_total{job=~".*thanos-receiver-compact.*"}[5m]))
          * 100 > 5
          )
        for: 15m
        labels:
          severity: warning
      - alert: ThanosCompactHasNotRun
        annotations:
          description: Thanos Compact {{$labels.job}} has not uploaded anything for 24
            hours.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanoscompacthasnotrun
          summary: Thanos Compact has not uploaded anything for last 24 hours.
        expr:
          (time() - max by (cluster, job) (max_over_time(thanos_objstore_bucket_last_successful_upload_time{job=~".*thanos-receiver-compact.*"}[24h])))
          / 60 / 60 > 24
        labels:
          severity: warning
  - name: thanos-query
    rules:
      - alert: ThanosQueryHttpRequestQueryErrorRateHigh
        annotations:
          description: Thanos Query {{$labels.job}} is failing to handle {{$value | humanize}}%
            of "query" requests.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryhttprequestqueryerrorratehigh
          summary: Thanos Query is failing to handle requests.
        expr: |
          (
            sum by (cluster, job) (rate(http_requests_total{code=~"5..", job=~".*thanos-query-query", handler="query"}[5m]))
          /
            sum by (cluster, job) (rate(http_requests_total{job=~".*thanos-query-query", handler="query"}[5m]))
          ) * 100 > 5
        for: 5m
        labels:
          severity: critical
      - alert: ThanosQueryHttpRequestQueryRangeErrorRateHigh
        annotations:
          description: Thanos Query {{$labels.job}} is failing to handle {{$value | humanize}}%
            of "query_range" requests.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryhttprequestqueryrangeerrorratehigh
          summary: Thanos Query is failing to handle requests.
        expr: |
          (
            sum by (cluster, job) (rate(http_requests_total{code=~"5..", job=~".*thanos-query-query", handler="query_range"}[5m]))
          /
            sum by (cluster, job) (rate(http_requests_total{job=~".*thanos-query-query", handler="query_range"}[5m]))
          ) * 100 > 5
        for: 5m
        labels:
          severity: critical
      - alert: ThanosQueryGrpcServerErrorRate
        annotations:
          description: Thanos Query {{$labels.job}} is failing to handle {{$value | humanize}}%
            of requests.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosquerygrpcservererrorrate
          summary: Thanos Query is failing to handle requests.
        expr: |
          (
            sum by (cluster, job) (rate(grpc_server_handled_total{grpc_code=~"Unknown|ResourceExhausted|Internal|Unavailable|DataLoss|DeadlineExceeded", job=~".*thanos-query-query"}[5m]))
          /
            sum by (cluster, job) (rate(grpc_server_started_total{job=~".*thanos-query-query"}[5m]))
          * 100 > 5
          )
        for: 5m
        labels:
          severity: warning
      - alert: ThanosQueryGrpcClientErrorRate
        annotations:
          description: Thanos Query {{$labels.job}} is failing to send {{$value | humanize}}%
            of requests.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosquerygrpcclienterrorrate
          summary: Thanos Query is failing to send requests.
        expr: |
          (
            sum by (cluster, job) (rate(grpc_client_handled_total{grpc_code!="OK", job=~".*thanos-query-query"}[5m]))
          /
            sum by (cluster, job) (rate(grpc_client_started_total{job=~".*thanos-query-query"}[5m]))
          ) * 100 > 5
        for: 5m
        labels:
          severity: warning
      - alert: ThanosQueryHighDNSFailures
        annotations:
          description: Thanos Query {{$labels.job}} have {{$value | humanize}}% of failing
            DNS queries for store endpoints.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryhighdnsfailures
          summary: Thanos Query is having high number of DNS failures.
        expr: |
          (
            sum by (cluster, job) (rate(thanos_query_store_apis_dns_failures_total{job=~".*thanos-query-query"}[5m]))
          /
            sum by (cluster, job) (rate(thanos_query_store_apis_dns_lookups_total{job=~".*thanos-query-query"}[5m]))
          ) * 100 > 1
        for: 15m
        labels:
          severity: warning
      - alert: ThanosQueryInstantLatencyHigh
        annotations:
          description: Thanos Query {{$labels.job}} has a 99th percentile latency of {{$value}}
            seconds for instant queries.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryinstantlatencyhigh
          summary: Thanos Query has high latency for queries.
        expr: |
          (
            histogram_quantile(0.99, sum by (job, le) (rate(http_request_duration_seconds_bucket{job=~".*thanos-query-query", handler="query"}[5m]))) > 40
          and
            sum by (cluster, job) (rate(http_request_duration_seconds_bucket{job=~".*thanos-query-query", handler="query"}[5m])) > 0
          )
        for: 10m
        labels:
          severity: critical
      - alert: ThanosQueryRangeLatencyHigh
        annotations:
          description: Thanos Query {{$labels.job}} has a 99th percentile latency of {{$value}}
            seconds for range queries.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryrangelatencyhigh
          summary: Thanos Query has high latency for queries.
        expr: |
          (
            histogram_quantile(0.99, sum by (job, le) (rate(http_request_duration_seconds_bucket{job=~".*thanos-query-query", handler="query_range"}[5m]))) > 90
          and
            sum by (cluster, job) (rate(http_request_duration_seconds_count{job=~".*thanos-query-query", handler="query_range"}[5m])) > 0
          )
        for: 10m
        labels:
          severity: critical
  - name: thanos-receive
    rules:
      - alert: ThanosReceiveHttpRequestErrorRateHigh
        annotations:
          description: Thanos Receive {{$labels.job}} is failing to handle {{$value |
            humanize}}% of requests.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosreceivehttprequesterrorratehigh
          summary: Thanos Receive is failing to handle requests.
        expr: |
          (
            sum by (cluster, job) (rate(http_requests_total{code=~"5..", job=~".*thanos-receiver-receive.*", handler="receive"}[5m]))
          /
            sum by (cluster, job) (rate(http_requests_total{job=~".*thanos-receiver-receive.*", handler="receive"}[5m]))
          ) * 100 > 5
        for: 20m
        labels:
          severity: critical
      - alert: ThanosReceiveHttpRequestLatencyHigh
        annotations:
          description: Thanos Receive {{$labels.job}} has a 99th percentile latency of
            {{ $value }} seconds for requests.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosreceivehttprequestlatencyhigh
          summary: Thanos Receive has high HTTP requests latency.
        expr: |
          (
            histogram_quantile(0.99, sum by (cluster, job, le) (rate(http_request_duration_seconds_bucket{job=~".*thanos-receiver-receive.*", handler="receive"}[5m]))) > 10
          and
            sum by (cluster, job) (rate(http_request_duration_seconds_count{job=~".*thanos-receiver-receive.*", handler="receive"}[5m])) > 0
          )
        for: 10m
        labels:
          severity: critical
      - alert: ThanosReceiveHighReplicationFailures
        annotations:
          description: Thanos Receive {{$labels.job}} is failing to replicate {{$value
            | humanize}}% of requests.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosreceivehighreplicationfailures
          summary: Thanos Receive is having high number of replication failures.
        expr: |
          thanos_receive_replication_factor > 1
            and
          (
            (
              sum by (cluster, job) (rate(thanos_receive_replications_total{result="error", job=~".*thanos-receiver-receive.*"}[5m]))
            /
              sum by (cluster, job) (rate(thanos_receive_replications_total{job=~".*thanos-receiver-receive.*"}[5m]))
            )
            >
            (
              max by (cluster, job) (floor((thanos_receive_replication_factor{job=~".*thanos-receiver-receive.*"}+1) / 2))
            /
              max by (cluster, job) (thanos_receive_hashring_nodes{job=~".*thanos-receiver-receive.*"})
            )
          ) * 100
        for: 5m
        labels:
          severity: warning
      - alert: ThanosReceiveHighForwardRequestFailures
        annotations:
          description: Thanos Receive {{$labels.job}} is failing to forward {{$value |
            humanize}}% of requests.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosreceivehighforwardrequestfailures
          summary: Thanos Receive is failing to forward requests.
        expr: |
          (
            sum by (cluster, job) (rate(thanos_receive_forward_requests_total{result="error", job=~".*thanos-receiver-receive.*"}[5m]))
          /
            sum by (cluster, job) (rate(thanos_receive_forward_requests_total{job=~".*thanos-receiver-receive.*"}[5m]))
          ) * 100 > 20
        for: 5m
        labels:
          severity: info
      - alert: ThanosReceiveHighHashringFileRefreshFailures
        annotations:
          description: Thanos Receive {{$labels.job}} is failing to refresh hashring file,
            {{$value | humanize}} of attempts failed.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosreceivehighhashringfilerefreshfailures
          summary: Thanos Receive is failing to refresh hasring file.
        expr: |
          (
            sum by (cluster, job) (rate(thanos_receive_hashrings_file_errors_total{job=~".*thanos-receiver-receive.*"}[5m]))
          /
            sum by (cluster, job) (rate(thanos_receive_hashrings_file_refreshes_total{job=~".*thanos-receiver-receive.*"}[5m]))
          > 0
          )
        for: 15m
        labels:
          severity: warning
      - alert: ThanosReceiveConfigReloadFailure
        annotations:
          description: Thanos Receive {{$labels.job}} has not been able to reload hashring
            configurations.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosreceiveconfigreloadfailure
          summary: Thanos Receive has not been able to reload configuration.
        expr: avg by (cluster, job) (thanos_receive_config_last_reload_successful{job=~".*thanos-receiver-receive.*"})
          != 1
        for: 5m
        labels:
          severity: warning
      - alert: ThanosReceiveNoUpload
        annotations:
          description: Thanos Receive {{$labels.instance}} has not uploaded latest data
            to object storage.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosreceivenoupload
          summary: Thanos Receive has not uploaded latest data to object storage.
        expr: |
          (up{job=~".*thanos-receiver-receive.*"} - 1)
          + on (cluster, job, instance) # filters to only alert on current instance last 3h
          (sum by (cluster, job, instance) (increase(thanos_shipper_uploads_total{job=~".*thanos-receiver-receive.*"}[3h])) == 0)
        for: 3h
        labels:
          severity: critical
      - alert: ThanosReceiveTrafficBelowThreshold
        annotations:
          description: At Thanos Receive {{$labels.job}} in {{$labels.namespace}} , the
            average 1-hr avg. metrics ingestion rate  is {{$value | humanize}}% of 12-hr
            avg. ingestion rate.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosreceivetrafficbelowthreshold
          summary: Thanos Receive is experiencing low avg. 1-hr ingestion rate relative
            to avg. 12-hr ingestion rate.
        expr: |
          (
            avg_over_time(rate(http_requests_total{job=~".*thanos-receiver-receive.*", code=~"2..", handler="receive"}[5m])[1h:5m])
          /
            avg_over_time(rate(http_requests_total{job=~".*thanos-receiver-receive.*", code=~"2..", handler="receive"}[5m])[12h:5m])
          ) * 100 < 50
        for: 1h
        labels:
          severity: warning
  - name: thanos-store
    rules:
      - alert: ThanosStoreGrpcErrorRate
        annotations:
          description: Thanos Store {{$labels.job}} is failing to handle {{$value | humanize}}%
            of requests.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosstoregrpcerrorrate
          summary: Thanos Store is failing to handle qrpcd requests.
        expr: |
          (
            sum by (cluster, job) (rate(grpc_server_handled_total{grpc_code=~"Unknown|ResourceExhausted|Internal|Unavailable|DataLoss|DeadlineExceeded", job=~".*thanos-receiver-store.*"}[5m]))
          /
            sum by (cluster, job) (rate(grpc_server_started_total{job=~".*thanos-receiver-store.*"}[5m]))
          * 100 > 5
          )
        for: 5m
        labels:
          severity: warning
      - alert: ThanosStoreSeriesGateLatencyHigh
        annotations:
          description: Thanos Store {{$labels.job}} has a 99th percentile latency of {{$value}}
            seconds for store series gate requests.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosstoreseriesgatelatencyhigh
          summary: Thanos Store has high latency for store series gate requests.
        expr: |
          (
            histogram_quantile(0.99, sum by (job, le) (rate(thanos_bucket_store_series_gate_duration_seconds_bucket{job=~".*thanos-receiver-store.*"}[5m]))) > 2
          and
            sum by (cluster, job) (rate(thanos_bucket_store_series_gate_duration_seconds_count{job=~".*thanos-receiver-store.*"}[5m])) > 0
          )
        for: 10m
        labels:
          severity: warning
      - alert: ThanosStoreBucketHighOperationFailures
        annotations:
          description: Thanos Store {{$labels.job}} Bucket is failing to execute {{$value
            | humanize}}% of operations.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosstorebuckethighoperationfailures
          summary: Thanos Store Bucket is failing to execute operations.
        expr: |
          (
            sum by (cluster, job) (rate(thanos_objstore_bucket_operation_failures_total{job=~".*thanos-receiver-store.*"}[5m]))
          /
            sum by (cluster, job) (rate(thanos_objstore_bucket_operations_total{job=~".*thanos-receiver-store.*"}[5m]))
          * 100 > 5
          )
        for: 15m
        labels:
          severity: warning
      - alert: ThanosStoreObjstoreOperationLatencyHigh
        annotations:
          description: Thanos Store {{$labels.job}} Bucket has a 99th percentile latency
            of {{$value}} seconds for the bucket operations.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosstoreobjstoreoperationlatencyhigh
          summary: Thanos Store is having high latency for bucket operations.
        expr: |
          (
            histogram_quantile(0.99, sum by (job, le) (rate(thanos_objstore_bucket_operation_duration_seconds_bucket{job=~".*thanos-receiver-store.*"}[5m]))) > 2
          and
            sum by (cluster, job) (rate(thanos_objstore_bucket_operation_duration_seconds_count{job=~".*thanos-receiver-store.*"}[5m])) > 0
          )
        for: 10m
        labels:
          severity: warning
  - name: thanos-bucket-replicate
    rules:
      - alert: ThanosBucketReplicateErrorRate
        annotations:
          description: Thanos Replicate is failing to run, {{$value | humanize}}% of attempts
            failed.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosbucketreplicateerrorrate
          summary: Thanos Replicate is failing to run.
        expr: |
          (
            sum by (cluster, job) (rate(thanos_replicate_replication_runs_total{result="error", job=~".*thanos-receiver-bucket-replicate.*"}[5m]))
          / on (cluster, job) group_left
            sum by (cluster, job) (rate(thanos_replicate_replication_runs_total{job=~".*thanos-receiver-bucket-replicate.*"}[5m]))
          ) * 100 >= 10
        for: 5m
        labels:
          severity: critical
      - alert: ThanosBucketReplicateRunLatency
        annotations:
          description: Thanos Replicate {{$labels.job}} has a 99th percentile latency
            of {{$value}} seconds for the replicate operations.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosbucketreplicaterunlatency
          summary: Thanos Replicate has a high latency for replicate operations.
        expr: |
          (
            histogram_quantile(0.99, sum by (cluster, job) (rate(thanos_replicate_replication_run_duration_seconds_bucket{job=~".*thanos-receiver-bucket-replicate.*"}[5m]))) > 20
          and
            sum by (cluster, job) (rate(thanos_replicate_replication_run_duration_seconds_bucket{job=~".*thanos-receiver-bucket-replicate.*"}[5m])) > 0
          )
        for: 5m
        labels:
          severity: critical
  - name: thanos-component-absent
    rules:
      - alert: ThanosCompactIsDown
        annotations:
          description: ThanosCompact has disappeared. Prometheus target for the component
            cannot be discovered.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanoscompactisdown
          summary: Thanos component has disappeared.
        expr: |
          absent(up{job=~".*thanos-receiver-compact.*"} == 1)
        for: 5m
        labels:
          severity: critical
      - alert: ThanosQueryIsDown
        annotations:
          description: ThanosQuery has disappeared. Prometheus target for the component
            cannot be discovered.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryisdown
          summary: Thanos component has disappeared.
        expr: |
          absent(up{job=~".*thanos-query-query"} == 1)
        for: 5m
        labels:
          severity: critical
      - alert: ThanosReceiveIsDown
        annotations:
          description: ThanosReceive has disappeared. Prometheus target for the component
            cannot be discovered.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosreceiveisdown
          summary: Thanos component has disappeared.
        expr: |
          absent(up{job=~".*thanos-receiver-receive.*"} == 1)
        for: 5m
        labels:
          severity: critical
      - alert: ThanosStoreIsDown
        annotations:
          description: ThanosStore has disappeared. Prometheus target for the component
            cannot be discovered.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosstoreisdown
          summary: Thanos component has disappeared.
        expr: |
          absent(up{job=~".*thanos-receiver-store.*"} == 1)
        for: 5m
        labels:
          severity: critical
