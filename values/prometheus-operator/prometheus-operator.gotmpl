{{- $v := .Environment.Values }}
{{- $p := $v | get "prometheus-operator" }}
{{ $promHost := printf "prometheus.%s" $v.domain }}
{{ $alertsHost := printf "alertmanager.%s" $v.domain }}
{{ $grafanaHost := printf "grafana.%s" $v.domain }}
nameOverride: po
fullnameOverride: po
global:
  rbac:
    pspEnabled: false
coreDns:
  enabled: false    
kubeEtcd:
  enabled: false    
prometheusOperator:
  configReloaderCpu: 200m
  admissionWebhooks:
    enabled: false
  tlsProxy:
    enabled: false
  createCustomResource: true
prometheus:
  prometheusSpec:
    podMetadata:
      annotations:
        sidecar.istio.io/inject: "false"
    portName: http-web
    storageSpec:
      volumeClaimTemplate:
        metadata:
          name: promdata
        spec:
          storageClassName: fast
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 5Gi
    enableAdminAPI: true
    externalUrl: https://{{ $promHost }}
    # additionalScrapeConfigs:
    #   - job_name: 'probe-sites'
    #     metrics_path: /probe
    #     params:
    #       module: [http_2xx]  # Look for a HTTP 200 response.
    #     static_configs:
    #       - targets:
    #         {{ range $site := $v.sites }}
    #         - https://{{ $site }}
    #         {{- end }}
    #     relabel_configs:
    #       - source_labels: [__address__]
    #         target_label: __param_target
    #       - source_labels: [__param_target]
    #         target_label: instance
    #       - target_label: __address__
    #         replacement: prom-blackbox-exporter:9115
  additionalServiceMonitors:
    {{- readFile "service-monitors.yaml" | nindent 4 }}      
additionalPrometheusRules:
  # - name: blackbox
  #   {{/*- readFile "rules/blackbox.yaml" | nindent 4 */}}
  - name: cluster-autoscaler
    {{- readFile "rules/cluster-autoscaler.yaml" | nindent 4 }}
alertmanager:
  alertmanagerSpec:
    podMetadata:
      annotations:
        sidecar.istio.io/inject: "false"
    portName: http-web
    externalUrl: https://{{ $alertsHost }}
    # logFormat: logfmt # @todo: remove if in master: https://github.com/helm/charts/pull/15330
  config:
    global:
      slack_api_url: {{ $p.alertmanager.slackUrl }}
    route:
      receiver: default
      group_by: [alertname] #alertname
      group_interval: {{ $p.alertmanager.groupInterval }}
      repeat_interval: {{ $p.alertmanager.repeatInterval }}
      routes:
        - match:
            alertname: Watchdog
          receiver: "null"
        - match:
            severity: critical
          receiver: critical
    receivers:
      - name: "null"
      - name: default
        slack_configs:
          - channel: "#mon-{{ $p.alertmanager.channelGroup }}-{{ $v.provider }}-{{ $v.stage }}"
            {{- readFile "slack-configs.yaml" | nindent 12 }}
      - name: critical
        slack_configs:
          - channel: "#mon-{{ $p.alertmanager.channelGroup }}-{{ $v.provider }}-{{ $v.stage }}-crit"
            {{- readFile "slack-configs.yaml" | nindent 12 }}
grafana:
  rbac:
    pspUseAppArmor: false
    pspEnabled: false
  # sidecar:
  #   dashboards:
  #     enabled: false
  podAnnotations:
    sidecar.istio.io/inject: "false"
  plugins:
    - grafana-piechart-panel
  additionalDataSources:
    - name: Graphite
      editable: false
      type: graphite
      access: proxy
      url: http://graphite:80
    - name: Loki
      editable: false
      type: loki
      access: proxy
      url: http://loki:3100
  customerLabels: {{ toYaml $v.customerLabels | nindent 4 }}
  adminPassword: bladibla
  service:
    portName: http-service
  grafana.ini:
    log:
      level: debug
    server:
      root_url: https://{{ $grafanaHost }}
    users:
      allow_sign_up: false
      auto_assign_org: true
      auto_assign_org_role: Admin

commonLabels: {{ toYaml $v.customerLabels | nindent 2 }}
kube-state-metrics:
  podSecurityPolicy:
    enabled: false
  customerLabels: {{ toYaml $v.customerLabels | nindent 4 }}
prometheus-node-exporter:
  rbac:
    pspEnabled: false
  customerLabels: {{ toYaml $v.customerLabels | nindent 4 }}

kubeControllerManager:
  enabled: false
kubeScheduler:
  enabled: false