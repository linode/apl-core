{{- $v := .Values }}
{{- $c := $v.charts }}
{{- $k := $v.charts | get "keycloak" dict }}
{{- $p := $v.charts | get "prometheus-operator" dict }}
{{- $stage := $v.charts | get "cert-manager.stage" }}
{{- $hasKeycloak := $k | get "enabled" true }}
{{- $realm := $k | get "realm" "master" }}
{{- $keycloakBase := printf "https://keycloak.%s/realms/%s" $v.cluster.domainSuffix $realm }}
{{- $appsDomain := printf "apps.%s" $v.cluster.domainSuffix }}
{{- $slackTpl := tpl (readFile "../../helmfile.d/snippets/slack.gotmpl") $v | toString }}
{{- $grafanaIni := tpl (readFile "../../helmfile.d/snippets/grafana.gotmpl") (dict "keycloakBase" $keycloakBase "hasKeycloak" $hasKeycloak "oidc" $v.oidc "stage" $stage "keycloak" ($k | get "idp")) | toString }}

nameOverride: po
fullnameOverride: po
coreDns:
  enabled: false
global:
  rbac:
    pspEnabled: false
{{- if $v.otomi.isManaged }}
kubeEtcd:
  enabled: false
kubeControllerManager:
  enabled: false
kubeScheduler:
  enabled: false
kubeProxy:
  enabled: false
{{- end }}
prometheusOperator:
  configReloaderCpu: 50m
  configReloaderMemory: 64Mi
  podAnnotations:
    sidecar.istio.io/inject: "false"
  resources:
    limits:
      cpu: 400m
      memory: 256Mi
    requests:
      cpu: 100m
      memory: 128Mi
  admissionWebhooks:
    enabled: false
  tlsProxy:
    enabled: false
  createCustomResource: false # chart 8.2.0 version
  manageCrds: false # chart > 8.2.0
  kubeletService:
    enabled: true
  priorityClassName: "otomi-critical"
commonLabels:
  prometheus: system
prometheus:
  prometheusSpec:
    serviceMonitorSelector:
      matchLabels:
        prometheus: system
    resources:
      {{- with $p | get "resources.prometheus" nil }}
        {{- toYaml . | nindent 6 }}
      {{- else }}
      requests:
        cpu: 100m
        memory: 512Mi
      limits:
        cpu: '3'
        memory: 3Gi
      {{- end }}
    priorityClassName: "otomi-critical"
    externalLabels:
      cluster: {{ printf "%s/%s/%s" $v.customer.name $v.cluster.provider $v.cluster.name | lower | quote }}
    portName: http-web
    storageSpec:
      volumeClaimTemplate:
        metadata:
          name: promdata
        spec:
          storageClassName: fast
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: {{ $p | get "prometheus.storageSize" "5Gi" }}
    enableAdminAPI: true
    externalUrl: https://{{ $appsDomain }}/prometheus
  additionalServiceMonitors: {{- readFile "service-monitors.yaml" | nindent 4 }}
{{ if eq $v.cluster.provider "aws" }}  
additionalPrometheusRules:
  - name: cluster-autoscaler
    {{- readFile "rules/cluster-autoscaler.yaml" | nindent 4 }}
{{- end }}
alertmanager:
  alertmanagerSpec:
    priorityClassName: "otomi-critical"
    resources:
      requests:
        memory: 128Mi
        cpu: 100m
      limits:
        memory: 256Mi
        cpu: 500m
    portName: http-web
    externalUrl: https://{{ $appsDomain }}/alertmanager
  config: {{- tpl (readFile "../../helmfile.d/snippets/alertmanager.gotmpl") (dict "instance" $v "root" $v "slackTpl" $slackTpl) | nindent 4 }}
grafana:
  downloadDashboards:
    resources:
      limits:
        cpu: 100m
        memory: 100Mi
      requests:
        cpu: 50m
        memory: 50Mi
  image:
    tag: 7.5.6
  initChownData:
    resources:
      limits:
        cpu: 100m
        memory: 128Mi
      requests:
        cpu: 100m
        memory: 128Mi
  resources:
    {{- with $p | get "resources.grafana" nil }}
      {{- toYaml . | nindent 4 }}
    {{- else }}
    requests:
      memory: 128Mi
      cpu: 100m
    limits:
      memory: 256Mi
      cpu: 500m
    {{- end }}
  sidecar:
    resources:
      limits:
        cpu: 100m
        memory: 100Mi
      requests:
        cpu: 50m
        memory: 50Mi
  nameOverride: po-grafana
  fullnameOverride: po-grafana
  rbac:
    pspUseAppArmor: false
    pspEnabled: false
  podAnnotations:
    sidecar.istio.io/inject: "true"

  testFramework:
    # enabled: true
    # image: "bats/bats"
    # tag: "v1.1.0"
    # imagePullPolicy: IfNotPresent
    securityContext: 
      runAsUser: 1000
    
  plugins:
    - grafana-piechart-panel
  additionalDataSources:
    - name: Loki
      editable: false
      type: loki
      access: proxy
      {{- if $v.otomi.isMultitenant }}
      url: http://loki:11811
      basicAuth: true
      basicAuthUser: admins
      basicAuthPassword: {{ $v.charts.loki.adminPassword }}
      {{- else }}
      url: http://loki:3100
      {{- end }}
    {{- if $v | get "azure.monitor" nil }}
    - {{- tpl (readFile "../../helmfile.d/snippets/azure-monitor.gotmpl") $v.azure.monitor | toString | nindent 6 }}
    {{- end }}
    {{- if $c | get "sitespeed.enabled" false }}
    - name: Graphite
      editable: false
      type: graphite
      access: proxy
      url: http://graphite:80
    {{- end }}
  adminPassword: {{ $p | get "grafana.adminPassword" $v.otomi.adminPassword }}
  service:
    portName: http-service
  grafana.ini: {{- $grafanaIni | nindent 4 }}
    server:
      root_url: https://{{ $appsDomain }}/grafana

kube-state-metrics:
  # image:
  #   tag: v1.8.0
  # collectors:
  #   networkpolicies: false
  #   mutatingwebhookconfigurations: false
  #   validatingwebhookconfigurations: false
  #   volumeattachments: false
  #   verticalpodautoscalers: false
  # podAnnotations:
  #   sidecar.istio.io/inject: "false"
  resources:
    requests:
      memory: 128Mi
      cpu: 100m
    limits:
      memory: 256Mi
      cpu: 400m
  podSecurityPolicy:
    enabled: false

prometheus-node-exporter:
  resources:
    requests:
      memory: 128Mi
      cpu: 100m
    limits:
      memory: 128Mi
      cpu: 500m
  rbac:
    pspEnabled: false
  priorityClassName: "otomi-critical"
  podAnnotations:
    policy.otomi.io/ignore: psp-host-filesystem,psp-host-networking-ports,psp-host-security

