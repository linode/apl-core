{{- $v := .Values }}
{{- $vl:= $v.apps.thanos }}
{{- $obj := $vl.objstore }}
{{- $sp := $obj.storageProvider }}

## @section Thanos Query parameters
query:
  enabled: true
  replicaCount: {{ $vl.query.replicaCount }}
  service:
    additionalHeadless: true
  dnsDiscovery:
    enabled: false
  stores:
    - "thanos-storegateway:10901"
    - "dnssrv+_grpc._tcp.thanos-storegateway.monitoring.svc"
    - "dnssrv+_grpc._tcp.thanos-receive-headless.monitoring.svc"
  resources: {{- $vl.resources.query | toYaml | nindent 4 }}
  extraFlags:
    - "--query.auto-downsampling"

## @section Thanos Query Frontend parameters
queryFrontend:
  enabled: true
  resources: {{- $vl.resources.queryFrontend | toYaml | nindent 4 }}

## @section Thanos Bucket Web parameters
bucketweb:
  enabled: true
  resources: {{- $vl.resources.bucketweb | toYaml | nindent 4 }}

## @section Thanos Compactor parameters
compactor:
  enabled: true
  ## By default, there is NO retention set for object storage data. This means that data is stored forever, 
  ## which is a valid and recommended way of running Thanos.
  retentionResolutionRaw: {{ $vl.compactor.retentionResolutionRaw }}
  retentionResolution5m: {{ $vl.compactor.retentionResolution5m }}
  retentionResolution1h: {{ $vl.compactor.retentionResolution1h }}
  persistence:
    size: {{ $vl.persistence.compactor.size }}
  resources: {{- $vl.resources.compactor | toYaml | nindent 4 }}

## @section Thanos Store Gateway parameters
storegateway:
  enabled: true
  persistence:
    size: {{ $vl.persistence.storegateway.size }}
  resources: {{- $vl.resources.storegateway | toYaml | nindent 4 }}

## @section Thanos Receive parameters
receive:
  enabled: true
  mode: {{ $vl.receiver.mode }}
  replicaCount: {{ $vl.receiver.replicaCount }}
  persistence:
    enabled: true
    size: {{ $vl.persistence.receiver.size }}
  resources: {{- $vl.resources.receiver | toYaml | nindent 4 }}
  tsdbRetention: {{ $vl.receiver.tsdbRetention }}
  replicationFactor: {{ $vl.receiver.replicationFactor }}
  service:
    additionalHeadless: true

## @section Thanos Ruler parameters
receiveDistributor:
  enabled: {{ $vl.receiverDistributor.enabled }}
  resources: {{- $vl.resources.receiverDistributor | toYaml | nindent 4 }}

## @section Thanos Ruler parameters
ruler:
  enabled: {{ $vl.ruler.enabled }}
  persistence:
    size: {{ $vl.persistence.ruler.size }}
  resources: {{- $vl.resources.ruler | toYaml | nindent 4 }}
  alertmanagers:
    - "dnssrv+http://_http-web._tcp.alertmanager-operated.monitoring.svc"
  service:
    additionalHeadless: true
  queries:
    - dnssrv+_http._tcp.thanos-query-headless.monitoring.svc
  clusterName: {{ $v.cluster.domainSuffix }}
  extraFlags:
    - --rule-file=/conf/rules/*.yaml
  config: |-
    groups:
    - name: thanos-compact
      rules:
      - alert: ThanosCompactMultipleRunning
        annotations:
          description: No more than one Thanos Compact instance should be running at once.
            There are {{$value}} instances running.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanoscompactmultiplerunning
          summary: Thanos Compact has multiple instances running.
        expr: sum by (cluster, job) (up{job=~".*thanos-receiver-compact.*"}) > 1
        for: 5m
        labels:
          severity: warning
      - alert: ThanosCompactHalted
        annotations:
          description: Thanos Compact {{$labels.job}} has failed to run and now is halted.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanoscompacthalted
          summary: Thanos Compact has failed to run and is now halted.
        expr: thanos_compact_halted{job=~".*thanos-receiver-compact.*"} == 1
        for: 5m
        labels:
          severity: warning
      - alert: ThanosCompactHighCompactionFailures
        annotations:
          description: Thanos Compact {{$labels.job}} is failing to execute {{$value |
            humanize}}% of compactions.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanoscompacthighcompactionfailures
          summary: Thanos Compact is failing to execute compactions.
        expr: |
          (
            sum by (cluster, job) (rate(thanos_compact_group_compactions_failures_total{job=~".*thanos-receiver-compact.*"}[5m]))
          /
            sum by (cluster, job) (rate(thanos_compact_group_compactions_total{job=~".*thanos-receiver-compact.*"}[5m]))
          * 100 > 5
          )
        for: 15m
        labels:
          severity: warning
      - alert: ThanosCompactBucketHighOperationFailures
        annotations:
          description: Thanos Compact {{$labels.job}} Bucket is failing to execute {{$value
            | humanize}}% of operations.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanoscompactbuckethighoperationfailures
          summary: Thanos Compact Bucket is having a high number of operation failures.
        expr: |
          (
            sum by (cluster, job) (rate(thanos_objstore_bucket_operation_failures_total{job=~".*thanos-receiver-compact.*"}[5m]))
          /
            sum by (cluster, job) (rate(thanos_objstore_bucket_operations_total{job=~".*thanos-receiver-compact.*"}[5m]))
          * 100 > 5
          )
        for: 15m
        labels:
          severity: warning
      - alert: ThanosCompactHasNotRun
        annotations:
          description: Thanos Compact {{$labels.job}} has not uploaded anything for 24
            hours.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanoscompacthasnotrun
          summary: Thanos Compact has not uploaded anything for last 24 hours.
        expr: (time() - max by (cluster, job) (max_over_time(thanos_objstore_bucket_last_successful_upload_time{job=~".*thanos-receiver-compact.*"}[24h])))
          / 60 / 60 > 24
        labels:
          severity: warning
    - name: thanos-query
      rules:
      - alert: ThanosQueryHttpRequestQueryErrorRateHigh
        annotations:
          description: Thanos Query {{$labels.job}} is failing to handle {{$value | humanize}}%
            of "query" requests.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryhttprequestqueryerrorratehigh
          summary: Thanos Query is failing to handle requests.
        expr: |
          (
            sum by (cluster, job) (rate(http_requests_total{code=~"5..", job=~".*thanos-query-query", handler="query"}[5m]))
          /
            sum by (cluster, job) (rate(http_requests_total{job=~".*thanos-query-query", handler="query"}[5m]))
          ) * 100 > 5
        for: 5m
        labels:
          severity: critical
      - alert: ThanosQueryHttpRequestQueryRangeErrorRateHigh
        annotations:
          description: Thanos Query {{$labels.job}} is failing to handle {{$value | humanize}}%
            of "query_range" requests.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryhttprequestqueryrangeerrorratehigh
          summary: Thanos Query is failing to handle requests.
        expr: |
          (
            sum by (cluster, job) (rate(http_requests_total{code=~"5..", job=~".*thanos-query-query", handler="query_range"}[5m]))
          /
            sum by (cluster, job) (rate(http_requests_total{job=~".*thanos-query-query", handler="query_range"}[5m]))
          ) * 100 > 5
        for: 5m
        labels:
          severity: critical
      - alert: ThanosQueryGrpcServerErrorRate
        annotations:
          description: Thanos Query {{$labels.job}} is failing to handle {{$value | humanize}}%
            of requests.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosquerygrpcservererrorrate
          summary: Thanos Query is failing to handle requests.
        expr: |
          (
            sum by (cluster, job) (rate(grpc_server_handled_total{grpc_code=~"Unknown|ResourceExhausted|Internal|Unavailable|DataLoss|DeadlineExceeded", job=~".*thanos-query-query"}[5m]))
          /
            sum by (cluster, job) (rate(grpc_server_started_total{job=~".*thanos-query-query"}[5m]))
          * 100 > 5
          )
        for: 5m
        labels:
          severity: warning
      - alert: ThanosQueryGrpcClientErrorRate
        annotations:
          description: Thanos Query {{$labels.job}} is failing to send {{$value | humanize}}%
            of requests.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosquerygrpcclienterrorrate
          summary: Thanos Query is failing to send requests.
        expr: |
          (
            sum by (cluster, job) (rate(grpc_client_handled_total{grpc_code!="OK", job=~".*thanos-query-query"}[5m]))
          /
            sum by (cluster, job) (rate(grpc_client_started_total{job=~".*thanos-query-query"}[5m]))
          ) * 100 > 5
        for: 5m
        labels:
          severity: warning
      - alert: ThanosQueryHighDNSFailures
        annotations:
          description: Thanos Query {{$labels.job}} have {{$value | humanize}}% of failing
            DNS queries for store endpoints.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryhighdnsfailures
          summary: Thanos Query is having high number of DNS failures.
        expr: |
          (
            sum by (cluster, job) (rate(thanos_query_store_apis_dns_failures_total{job=~".*thanos-query-query"}[5m]))
          /
            sum by (cluster, job) (rate(thanos_query_store_apis_dns_lookups_total{job=~".*thanos-query-query"}[5m]))
          ) * 100 > 1
        for: 15m
        labels:
          severity: warning
      - alert: ThanosQueryInstantLatencyHigh
        annotations:
          description: Thanos Query {{$labels.job}} has a 99th percentile latency of {{$value}}
            seconds for instant queries.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryinstantlatencyhigh
          summary: Thanos Query has high latency for queries.
        expr: |
          (
            histogram_quantile(0.99, sum by (job, le) (rate(http_request_duration_seconds_bucket{job=~".*thanos-query-query", handler="query"}[5m]))) > 40
          and
            sum by (cluster, job) (rate(http_request_duration_seconds_bucket{job=~".*thanos-query-query", handler="query"}[5m])) > 0
          )
        for: 10m
        labels:
          severity: critical
      - alert: ThanosQueryRangeLatencyHigh
        annotations:
          description: Thanos Query {{$labels.job}} has a 99th percentile latency of {{$value}}
            seconds for range queries.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryrangelatencyhigh
          summary: Thanos Query has high latency for queries.
        expr: |
          (
            histogram_quantile(0.99, sum by (job, le) (rate(http_request_duration_seconds_bucket{job=~".*thanos-query-query", handler="query_range"}[5m]))) > 90
          and
            sum by (cluster, job) (rate(http_request_duration_seconds_count{job=~".*thanos-query-query", handler="query_range"}[5m])) > 0
          )
        for: 10m
        labels:
          severity: critical
    - name: thanos-receive
      rules:
      - alert: ThanosReceiveHttpRequestErrorRateHigh
        annotations:
          description: Thanos Receive {{$labels.job}} is failing to handle {{$value |
            humanize}}% of requests.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosreceivehttprequesterrorratehigh
          summary: Thanos Receive is failing to handle requests.
        expr: |
          (
            sum by (cluster, job) (rate(http_requests_total{code=~"5..", job=~".*thanos-receiver-receive.*", handler="receive"}[5m]))
          /
            sum by (cluster, job) (rate(http_requests_total{job=~".*thanos-receiver-receive.*", handler="receive"}[5m]))
          ) * 100 > 5
        for: 20m
        labels:
          severity: critical
      - alert: ThanosReceiveHttpRequestLatencyHigh
        annotations:
          description: Thanos Receive {{$labels.job}} has a 99th percentile latency of
            {{ $value }} seconds for requests.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosreceivehttprequestlatencyhigh
          summary: Thanos Receive has high HTTP requests latency.
        expr: |
          (
            histogram_quantile(0.99, sum by (cluster, job, le) (rate(http_request_duration_seconds_bucket{job=~".*thanos-receiver-receive.*", handler="receive"}[5m]))) > 10
          and
            sum by (cluster, job) (rate(http_request_duration_seconds_count{job=~".*thanos-receiver-receive.*", handler="receive"}[5m])) > 0
          )
        for: 10m
        labels:
          severity: critical
      - alert: ThanosReceiveHighReplicationFailures
        annotations:
          description: Thanos Receive {{$labels.job}} is failing to replicate {{$value
            | humanize}}% of requests.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosreceivehighreplicationfailures
          summary: Thanos Receive is having high number of replication failures.
        expr: |
          thanos_receive_replication_factor > 1
            and
          (
            (
              sum by (cluster, job) (rate(thanos_receive_replications_total{result="error", job=~".*thanos-receiver-receive.*"}[5m]))
            /
              sum by (cluster, job) (rate(thanos_receive_replications_total{job=~".*thanos-receiver-receive.*"}[5m]))
            )
            >
            (
              max by (cluster, job) (floor((thanos_receive_replication_factor{job=~".*thanos-receiver-receive.*"}+1) / 2))
            /
              max by (cluster, job) (thanos_receive_hashring_nodes{job=~".*thanos-receiver-receive.*"})
            )
          ) * 100
        for: 5m
        labels:
          severity: warning
      - alert: ThanosReceiveHighForwardRequestFailures
        annotations:
          description: Thanos Receive {{$labels.job}} is failing to forward {{$value |
            humanize}}% of requests.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosreceivehighforwardrequestfailures
          summary: Thanos Receive is failing to forward requests.
        expr: |
          (
            sum by (cluster, job) (rate(thanos_receive_forward_requests_total{result="error", job=~".*thanos-receiver-receive.*"}[5m]))
          /
            sum by (cluster, job) (rate(thanos_receive_forward_requests_total{job=~".*thanos-receiver-receive.*"}[5m]))
          ) * 100 > 20
        for: 5m
        labels:
          severity: info
      - alert: ThanosReceiveHighHashringFileRefreshFailures
        annotations:
          description: Thanos Receive {{$labels.job}} is failing to refresh hashring file,
            {{$value | humanize}} of attempts failed.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosreceivehighhashringfilerefreshfailures
          summary: Thanos Receive is failing to refresh hasring file.
        expr: |
          (
            sum by (cluster, job) (rate(thanos_receive_hashrings_file_errors_total{job=~".*thanos-receiver-receive.*"}[5m]))
          /
            sum by (cluster, job) (rate(thanos_receive_hashrings_file_refreshes_total{job=~".*thanos-receiver-receive.*"}[5m]))
          > 0
          )
        for: 15m
        labels:
          severity: warning
      - alert: ThanosReceiveConfigReloadFailure
        annotations:
          description: Thanos Receive {{$labels.job}} has not been able to reload hashring
            configurations.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosreceiveconfigreloadfailure
          summary: Thanos Receive has not been able to reload configuration.
        expr: avg by (cluster, job) (thanos_receive_config_last_reload_successful{job=~".*thanos-receiver-receive.*"})
          != 1
        for: 5m
        labels:
          severity: warning
      - alert: ThanosReceiveNoUpload
        annotations:
          description: Thanos Receive {{$labels.instance}} has not uploaded latest data
            to object storage.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosreceivenoupload
          summary: Thanos Receive has not uploaded latest data to object storage.
        expr: |
          (up{job=~".*thanos-receiver-receive.*"} - 1)
          + on (cluster, job, instance) # filters to only alert on current instance last 3h
          (sum by (cluster, job, instance) (increase(thanos_shipper_uploads_total{job=~".*thanos-receiver-receive.*"}[3h])) == 0)
        for: 3h
        labels:
          severity: critical
      - alert: ThanosReceiveTrafficBelowThreshold
        annotations:
          description: At Thanos Receive {{$labels.job}} in {{$labels.namespace}} , the
            average 1-hr avg. metrics ingestion rate  is {{$value | humanize}}% of 12-hr
            avg. ingestion rate.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosreceivetrafficbelowthreshold
          summary: Thanos Receive is experiencing low avg. 1-hr ingestion rate relative
            to avg. 12-hr ingestion rate.
        expr: |
          (
            avg_over_time(rate(http_requests_total{job=~".*thanos-receiver-receive.*", code=~"2..", handler="receive"}[5m])[1h:5m])
          /
            avg_over_time(rate(http_requests_total{job=~".*thanos-receiver-receive.*", code=~"2..", handler="receive"}[5m])[12h:5m])
          ) * 100 < 50
        for: 1h
        labels:
          severity: warning
    - name: thanos-store
      rules:
      - alert: ThanosStoreGrpcErrorRate
        annotations:
          description: Thanos Store {{$labels.job}} is failing to handle {{$value | humanize}}%
            of requests.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosstoregrpcerrorrate
          summary: Thanos Store is failing to handle qrpcd requests.
        expr: |
          (
            sum by (cluster, job) (rate(grpc_server_handled_total{grpc_code=~"Unknown|ResourceExhausted|Internal|Unavailable|DataLoss|DeadlineExceeded", job=~".*thanos-receiver-store.*"}[5m]))
          /
            sum by (cluster, job) (rate(grpc_server_started_total{job=~".*thanos-receiver-store.*"}[5m]))
          * 100 > 5
          )
        for: 5m
        labels:
          severity: warning
      - alert: ThanosStoreSeriesGateLatencyHigh
        annotations:
          description: Thanos Store {{$labels.job}} has a 99th percentile latency of {{$value}}
            seconds for store series gate requests.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosstoreseriesgatelatencyhigh
          summary: Thanos Store has high latency for store series gate requests.
        expr: |
          (
            histogram_quantile(0.99, sum by (job, le) (rate(thanos_bucket_store_series_gate_duration_seconds_bucket{job=~".*thanos-receiver-store.*"}[5m]))) > 2
          and
            sum by (cluster, job) (rate(thanos_bucket_store_series_gate_duration_seconds_count{job=~".*thanos-receiver-store.*"}[5m])) > 0
          )
        for: 10m
        labels:
          severity: warning
      - alert: ThanosStoreBucketHighOperationFailures
        annotations:
          description: Thanos Store {{$labels.job}} Bucket is failing to execute {{$value
            | humanize}}% of operations.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosstorebuckethighoperationfailures
          summary: Thanos Store Bucket is failing to execute operations.
        expr: |
          (
            sum by (cluster, job) (rate(thanos_objstore_bucket_operation_failures_total{job=~".*thanos-receiver-store.*"}[5m]))
          /
            sum by (cluster, job) (rate(thanos_objstore_bucket_operations_total{job=~".*thanos-receiver-store.*"}[5m]))
          * 100 > 5
          )
        for: 15m
        labels:
          severity: warning
      - alert: ThanosStoreObjstoreOperationLatencyHigh
        annotations:
          description: Thanos Store {{$labels.job}} Bucket has a 99th percentile latency
            of {{$value}} seconds for the bucket operations.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosstoreobjstoreoperationlatencyhigh
          summary: Thanos Store is having high latency for bucket operations.
        expr: |
          (
            histogram_quantile(0.99, sum by (job, le) (rate(thanos_objstore_bucket_operation_duration_seconds_bucket{job=~".*thanos-receiver-store.*"}[5m]))) > 2
          and
            sum by (cluster, job) (rate(thanos_objstore_bucket_operation_duration_seconds_count{job=~".*thanos-receiver-store.*"}[5m])) > 0
          )
        for: 10m
        labels:
          severity: warning
    - name: thanos-bucket-replicate
      rules:
      - alert: ThanosBucketReplicateErrorRate
        annotations:
          description: Thanos Replicate is failing to run, {{$value | humanize}}% of attempts
            failed.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosbucketreplicateerrorrate
          summary: Thanos Replicate is failing to run.
        expr: |
          (
            sum by (cluster, job) (rate(thanos_replicate_replication_runs_total{result="error", job=~".*thanos-receiver-bucket-replicate.*"}[5m]))
          / on (cluster, job) group_left
            sum by (cluster, job) (rate(thanos_replicate_replication_runs_total{job=~".*thanos-receiver-bucket-replicate.*"}[5m]))
          ) * 100 >= 10
        for: 5m
        labels:
          severity: critical
      - alert: ThanosBucketReplicateRunLatency
        annotations:
          description: Thanos Replicate {{$labels.job}} has a 99th percentile latency
            of {{$value}} seconds for the replicate operations.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosbucketreplicaterunlatency
          summary: Thanos Replicate has a high latency for replicate operations.
        expr: |
          (
            histogram_quantile(0.99, sum by (cluster, job) (rate(thanos_replicate_replication_run_duration_seconds_bucket{job=~".*thanos-receiver-bucket-replicate.*"}[5m]))) > 20
          and
            sum by (cluster, job) (rate(thanos_replicate_replication_run_duration_seconds_bucket{job=~".*thanos-receiver-bucket-replicate.*"}[5m])) > 0
          )
        for: 5m
        labels:
          severity: critical
    - name: thanos-component-absent
      rules:
      - alert: ThanosCompactIsDown
        annotations:
          description: ThanosCompact has disappeared. Prometheus target for the component
            cannot be discovered.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanoscompactisdown
          summary: Thanos component has disappeared.
        expr: |
          absent(up{job=~".*thanos-receiver-compact.*"} == 1)
        for: 5m
        labels:
          severity: critical
      - alert: ThanosQueryIsDown
        annotations:
          description: ThanosQuery has disappeared. Prometheus target for the component
            cannot be discovered.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosqueryisdown
          summary: Thanos component has disappeared.
        expr: |
          absent(up{job=~".*thanos-query-query"} == 1)
        for: 5m
        labels:
          severity: critical
      - alert: ThanosReceiveIsDown
        annotations:
          description: ThanosReceive has disappeared. Prometheus target for the component
            cannot be discovered.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosreceiveisdown
          summary: Thanos component has disappeared.
        expr: |
          absent(up{job=~".*thanos-receiver-receive.*"} == 1)
        for: 5m
        labels:
          severity: critical
      - alert: ThanosStoreIsDown
        annotations:
          description: ThanosStore has disappeared. Prometheus target for the component
            cannot be discovered.
          runbook_url: https://github.com/thanos-io/thanos/tree/main/mixin/runbook.md#alert-name-thanosstoreisdown
          summary: Thanos component has disappeared.
        expr: |
          absent(up{job=~".*thanos-receiver-store.*"} == 1)
        for: 5m
        labels:
          severity: critical

## @param objstoreConfig The [objstore configuration](https://thanos.io/tip/thanos/storage.md/)
## Specify content for objstore.yml
{{- if eq $sp.type "minioLocal" }}
objstoreConfig: |-
  type: s3
  config:
    bucket: thanos
    endpoint: minio.minio.svc.cluster.local:9000
    access_key: otomi-admin
    secret_key: {{ $v.otomi.adminPassword }}
    insecure: true
{{- end }}
{{- if eq $sp.type "s3" }}
objstoreConfig: |-
  type: s3
  config:
    bucket: {{ $sp.s3.bucket }}
    endpoint: {{ $sp.s3.s3Url }}
    access_key: {{ $sp.s3.accessKeyId }}
    secret_key: {{ $sp.s3.secretAccessKey }}
    insecure: true
{{- end }}

metrics:
  enabled: true
  serviceMonitor:
    enabled: true
    namespace: monitoring
    labels:
      prometheus: system