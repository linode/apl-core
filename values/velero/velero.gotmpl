{{- $v := .Values }}
{{- $vl := $v.apps.velero }}
{{- $pa := $v.backup.platform }}
{{- $cloud := $vl.cloud }}
{{- $storage := $vl.storage }}
{{- $cp := $cloud.provider | get "type" dict }}
{{- $sp := $storage.provider | get "type" dict }}

resources: {{- $vl.resources | toYaml | nindent 2 }}

metrics:
  enabled: true
  serviceMonitor:
    enabled: true
    additionalLabels:
      prometheus: system

initContainers:
  - name: velero-plugin-for-azure
    image: velero/velero-plugin-for-microsoft-azure:v1.5.0
    imagePullPolicy: IfNotPresent
    resources:
      requests:
        cpu: 50m
        memory: 32Mi
      limits:
        cpu: 100m
        memory: 32Mi
    volumeMounts:
      - mountPath: /target
        name: plugins
  - name: velero-plugin-for-aws
    image: velero/velero-plugin-for-aws:v1.4.0
    imagePullPolicy: IfNotPresent
    resources:
      requests:
        cpu: 50m
        memory: 32Mi
      limits:
        cpu: 100m
        memory: 32Mi
    volumeMounts:
      - mountPath: /target
        name: plugins

podSecurityContext:
  runAsUser: 1000

logLevel: {{ $vl.logLevel }}

configuration:
  {{- if eq $sp "azureBlob" }}
  provider: azure
  backupStorageLocation:
    name: otomi
    default: true
    bucket: {{ $storage.provider.azureBlob.bucket }}
    config:
      storageAccount: {{ $storage.provider.azureBlob.storageAccount }}
      resourceGroup: {{ $storage.provider.azureBlob.resourceGroup }}
  {{- end }}
  {{- if eq $sp "s3" }}
  provider: aws
  backupStorageLocation:
    name: otomi
    default: true
    bucket: {{ $storage.provider.s3.bucket }}
    config:
      s3Url: {{ $storage.provider.s3.s3Url }}
      region: {{ $storage.provider.s3.region }}
  {{- end }}
  {{- if eq $sp "minioLocal" }}
  provider: aws
  backupStorageLocation:
    name: otomi
    default: true
    bucket: velero   
    config:
      s3Url: http://minio.minio.svc.cluster.local:9000
      publicUrl: http://minio.minio.svc.cluster.local:9000
      region: minio
      s3ForcePathStyle: true
  {{- end }}

  {{- if eq $cp "azure" }}
  volumeSnapshotLocation:
    name: otomi
    config:
      resourceGroup: {{ $cloud.provider.azure.resourceGroup }}
  {{- end }}
  
  {{- if eq $cp "aws" }}
  volumeSnapshotLocation:
    name: otomi
    config:
      region: {{ $cp.region }}
  {{- end }}

  # if set Velero will back up all pod volumes using Restic with the exception of service account tokens, secrets, config maps and hostpath volumes
  defaultVolumesToRestic: true

credentials:
  secretContents:
    cloud: |
{{- if eq $cp "azure" }}
      AZURE_RESOURCE_GROUP={{ $cloud.provider.azure.resourceGroup }}
      AZURE_CLOUD_NAME={{ $cloud.provider.azure.environment }}
      AZURE_SUBSCRIPTION_ID={{ $cloud.provider.azure.subscriptionId }}
      AZURE_TENANT_ID={{ $cloud.provider.azure.tenantId }}
      AZURE_CLIENT_ID={{ $cloud.provider.azure.aadClientId }}
      AZURE_CLIENT_SECRET={{ $cloud.provider.azure.aadClientSecret }}
{{- end }}
{{- if and (eq $sp "azureBlob") (not (eq $cp "azure")) }}
      AZURE_SUBSCRIPTION_ID={{ $storage.provider.azureBlob.subscriptionId }}
      AZURE_TENANT_ID={{ $storage.provider.azureBlob.tenantId }}
      AZURE_CLIENT_ID={{ $storage.provider.azureBlob.aadClientId }}
      AZURE_CLIENT_SECRET={{ $storage.provider.azureBlob.aadClientSecret }}
{{- end }}
{{- if eq $sp "minioLocal" }}
      [default]
      aws_access_key_id=otomi-admin
      aws_secret_access_key={{ $v.otomi.adminPassword }}
{{- end }}
{{- if eq $sp "s3" }}
      [default]
      aws_access_key_id={{ $storage.storageProvider.s3.accessKeyId }}
      aws_secret_access_key={{ $storage.storageProvider.s3.secretAccessKey }}
{{- end }}

kubectl:
  # Resource requests/limits to specify for the upgrade/cleanup job.
  resources:
    requests:
      cpu: 50m
      memory: 32Mi
    limits:
      cpu: 100m
      memory: 32Mi
  labels: 
    # do not inject sidecar, so the kubectl k8s job can exit and return the completed status
    sidecar.istio.io/inject: "false"

deployRestic: true

schedules:
{{- if $pa.gitea.enabled }}
  gitea:
    disabled: false
    schedule: {{ $pa.gitea.schedule }}
    useOwnerReferencesInBackup: false
    template:
      ttl: {{ $pa.gitea.ttl }}
      includedNamespaces:
      - gitea
{{- end }}
{{- if $pa.keycloak.enabled }} 
  keycloak:
    disabled: false
    schedule: {{ $pa.keycloak.schedule }}
    useOwnerReferencesInBackup: false
    template:
      ttl: {{ $pa.keycloak.ttl }}
      includedNamespaces:
      - keycloak
{{- end }}
{{- if $pa.drone.enabled }} 
  drone:
    disabled: false
    schedule: {{ $pa.drone.schedule }}
    useOwnerReferencesInBackup: false
    template:
      ttl: {{ $pa.drone.ttl }}
      includedNamespaces:
      - drone
{{- end }}
{{- if $pa.harbor.enabled }} 
  harbor:
    disabled: false
    schedule: {{ $pa.harbor.schedule }}
    useOwnerReferencesInBackup: false
    template:
      ttl: {{ $pa.harbor.ttl }}
      includedNamespaces:
      - harbor
{{- end }}
{{- if $pa.vault.enabled }}
  vault:
    disabled: false
    schedule: {{ $pa.vault.schedule }}
    useOwnerReferencesInBackup: false
    template:
      ttl: {{ $pa.vault.ttl }}
      includedNamespaces:
      - vault
{{- end }}
{{- if $pa.argo.enabled }}
  argocd:
    disabled: false
    schedule: {{ $pa.argo.schedule }}
    useOwnerReferencesInBackup: false
    template:
      ttl: {{ $pa.argo.ttl }}
      includedNamespaces:
      - argocd
{{- end }}
{{- if $pa.kubeapps.enabled }}
  kubeapps:
    disabled: false
    schedule: {{ $pa.kubeapps.schedule }}
    useOwnerReferencesInBackup: false
    template:
      ttl: {{ $pa.kubeapps.ttl }}
      includedNamespaces:
      - kubeapps
{{- end }}
  # create backups of all team namespaces
{{- if $v.backup.teams.enabled }}
  {{- range $teamId := keys $v.teamConfig }}
  team-{{$teamId}}:
    disabled: false
    schedule: {{ $v.backup.teams.schedule }}
    useOwnerReferencesInBackup: false
    template:
      ttl: {{ $v.backup.teams.ttl }}
      includedNamespaces:
      - team-{{$teamId}}
  {{- end }}
{{- end }}