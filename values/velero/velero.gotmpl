{{- $v := .Values }}
{{- $vl := $v.apps.velero }}
{{- $obj := $v.obj.provider }}
{{- $bu := $v.obj.bucket }}

resources: {{- $vl.resources | toYaml | nindent 2 }}

upgradeJobResources: {{- $vl.resources | toYaml | nindent 2 }}

metrics:
  enabled: true
  serviceMonitor:
    enabled: true
    additionalLabels:
      prometheus: system

{{- if eq $v.cluster.provider "custom" }}
snapshotsEnabled: false
{{- end }}

upgradeCRDs: false
cleanUpCRDs: false

initContainers:
  - name: velero-plugin-for-aws
    image: velero/velero-plugin-for-aws:v1.8.2
    imagePullPolicy: IfNotPresent
    resources:
      requests:
        cpu: 50m
        memory: 32Mi
      limits:
        cpu: 100m
        memory: 32Mi
    volumeMounts:
      - mountPath: /target
        name: plugins
{{- if eq $v.cluster.provider "linode" }}
  - name: velero-plugin-for-linode
    image: displague/velero-plugin-linode:v0.0.1
    imagePullPolicy: IfNotPresent
    resources:
      requests:
        cpu: 50m
        memory: 32Mi
      limits:
        cpu: 100m
        memory: 512Mi
    volumeMounts:
      - mountPath: /target
        name: plugins
{{- end }}

podSecurityContext:
  runAsUser: 1000

configuration:
# Use restic for File System Backups instead of kopia
  uploaderType: restic
  defaultBackupStorageLocation: otomi
  {{- if eq $obj.type "minioLocal" }}
  backupStorageLocation:
  - name: default
    provider: aws
    default: true
    bucket: {{ $bu.velero}}   
    config:
      s3Url: http://minio.minio.svc.cluster.local:9000
      publicUrl: http://minio.minio.svc.cluster.local:9000
      region: minio
      s3ForcePathStyle: true
  {{- end }}
  {{- if eq $obj.type "linode" }}
  backupStorageLocation:
  - name: default
    provider: aws
    default: true
    bucket: {{ $bu.velero }} 
    config:
      s3Url: https://{{ $obj.linode.region }}.linodeobjects.com
      region: {{ $obj.linode.region }}
      s3ForcePathStyle: true
  {{- end }}
  {{- if eq $v.cluster.provider "linode" }}
  volumeSnapshotLocation:
  - name: default
    provider: linode.com/velero
  {{- end }}
  # if set Velero will back up all pod volumes using Restic with the exception of service account tokens, secrets, config maps and hostpath volumes
  defaultVolumesToRestic: {{ $vl.restic.enabled }}
  logLevel: {{ $vl.logLevel }}


credentials:
{{- if eq $v.cluster.provider "linode" }}
  extraEnvVars:
    LINODE_TOKEN: linode_token
{{- end }}
  secretContents:
    cloud: |
{{- if eq $obj.type "linode" }}
      [default]
      aws_access_key_id={{ $obj.linode.accessKeyId }}
      aws_secret_access_key={{ $obj.linode.secretAccessKey }}
{{- end }}
{{- if eq $obj.type "minioLocal" }}
      [default]
      aws_access_key_id=otomi-admin
      aws_secret_access_key={{ $v.otomi.adminPassword }}
{{- end }}
{{- if eq $v.cluster.provider "linode" }}
    linode_token: {{ $v.platformBackups.persistentVolumes.linodeApiToken }}
{{- end }}

kubectl:
  # Resource requests/limits to specify for the upgrade/cleanup job.
  resources:
    requests:
      cpu: 50m
      memory: 32Mi
    limits:
      cpu: 100m
      memory: 32Mi
  labels: 
    # do not inject sidecar, so the kubectl k8s job can exit and return the completed status
    sidecar.istio.io/inject: "false"

# Whether to deploy the node-agent daemonset.
# This parampeter is responsible for enabling restic(or kopia) to backup and restore volumes using File System Backup.
# Equivalent to running the velero install with --use-node-agent flag.
deployNodeAgent: {{ $vl.restic.enabled }}

nodeAgent:
  podSecurityContext:
    runAsUser: 1338
    fsGroup: 1338
